[
  {
    "path": "README.md",
    "content": "# CiscoÂ AIÂ BuildingÂ BlocksÂ â€”Â Agent Service\n\n![CiscoÂ AIÂ BuildingÂ Blocks](app/assets/ai_building_blocks.png)\n\n> **DISCLAIMERÂ â€”Â USEÂ ATÂ YOURÂ OWNÂ RISK**\n> This software is provided *â€œas isâ€*, without warranty of any kind. CiscoÂ Systems, Inc. and contributors shall not be liable for any claim, damages, or other liability arising from its use. This project is intended **solely for demonstration and development**. By using the code you acknowledge that you have read, understood, and accepted these terms.\n\n---\n\n## What is the AgentÂ Service?\n\nThe **AgentÂ Service** is the runtime half of the *CiscoÂ AIÂ Buildingâ€¯BlocksÂ Suite*.\n\n* **Agent Service (this repo)**Â â€” FastAPI microâ€‘service that merges an LLM, retrievalâ€‘augmented generation (RAG), and live Cisco platform APIs.\n* **Database Project**Â â€” companion pipeline that builds the vector indexes (AzureÂ AIÂ Search, Chroma, Elastic, â€¦) consumed by the Agent.\n\nTogether they form a turnkey sandbox for exploring Genâ€‘AIâ€‘powered automation on CiscoÂ Meraki, CatalystÂ Center, Spaces, Webex, and more.\n\n---\n\n## 1Â Â·Â Features\n\n| Capability                | Summary                                                                                                    |\n| ------------------------- | ---------------------------------------------------------------------------------------------------------- |\n| **Chat + RAG**            | Contextâ€‘aware chat backed by domain, APIâ€‘docs, and event indexes built by the DatabaseÂ Project.            |\n| **Function calling**      | The LLM can emit `function_call` JSON; a dispatcher triggers real Cisco REST APIs and returns live data.   |\n| **Unified Service layer** | One abstraction for Meraki, Catalyst, Spaces, Webex (extendable to Nexus, XDR, etc.).                      |\n| **Pluggable stack**       | Swap LLM (AzureÂ OpenAI, LlamaÂ 3, local HF) and vector backâ€‘end (Chroma, Azure Search, Elastic) viaÂ `.env`. |\n| **Static sample UI**      | A minimal HTML/JS frontâ€‘end in `static/` shows how to query the agent and render results.                  |\n\n---\n\n## 2Â Â·Â Highâ€‘Level Architecture\n\n```mermaid\nflowchart TD\n    subgraph Client\n        FE[Browser / CLI / Bot]\n    end\n\n    subgraph FastAPI[Agent Service]\n        CHAT[chat_routes.py] -->|may call| RETRIEVE[Retrievers]\n        CHAT -->|LLM chat| LLM[LLM Wrapper]\n        LLM -->|function_call| DISPATCH[Function Dispatcher]\n        DISPATCH --> SERVICE[Unified Cisco Service]\n        SERVICE -->|REST| MERAKI[Meraki API]\n        SERVICE --> CATALYST[CatalystÂ Center API]\n        SERVICE --> SPACES[Spaces API]\n        SERVICE --> WEBEX[Webex API]\n        RETRIEVE -->|vector| VDB[(VectorÂ DBs)]\n    end\n\n    FE --> CHAT\n```\n\n*VectorÂ DBs* are produced by the **CiscoÂ AIÂ BuildingÂ BlocksÂ Database** project.\n\n---\n\n\n## 3Â Â·Â Environment Blocks\n\nThe suite uses consistent envâ€‘var prefixes:\n\n* **DOMAIN\\_**\\*Â â€” domain knowledge / summaries layer\n* **FASTAPI\\_**\\*Â â€” APIâ€‘docs layer\n* **EVENTS\\_**\\*Â â€” raw events layer\n* **AGENTIC\\_**\\*Â â€” (reserved) future agentâ€‘ofâ€‘agents layer\n\nSee [`envâ€‘guide.md`](example_environment_variables_guide.MD) for a full cheatâ€‘sheet.\n\n---\n\n## 4Â Â·Â Extending theÂ Suite\n\n1. **Add a Cisco platform**Â â†’ implement a `CiscoXClient` + register in `unified_service.py`.\n2. **New vector store**Â â†’ write a retriever under `retrievers/` and set `<LAYER>_VECTOR_BACKEND`.\n3. **New LLM**Â â†’ implement `BaseLLM` subclass and configure `<LAYER>_LLM_PROVIDER`.\n\nPRs welcome!\n\n---\n\n## 5Â Â·Â License\n\nApacheÂ 2.0 â€¢ (c)Â 2025â€¯CiscoÂ Systems, Inc.\n\n---\n\n*Made with â¤ï¸Â by the Ciscoâ€¯AI BuildingÂ Blocks team.*\n"
  },
  {
    "path": "app/__init__.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/app/__init__.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n"
  },
  {
    "path": "app/config.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n# ai-building-blocks-agent/app/config.py\n# Copyright (c) 2025 Jeff Teeter\n# Cisco Systems, Inc.\n# Licensed under the Apache License, Version 2.0 (see LICENSE)\n# Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\"\"\"Centralised environment-variable resolver.\n\n*   Guarantees a **single source of truth** (no scattered ``os.getenv`` calls).\n*   Supports the hierarchical naming scheme::\n\n        <LAYER>_[<PROVIDER>_]KEY\n\n    Examples:\n        * ``FASTAPI_AZURE_LLM_MODEL=gpt-4o``\n        * ``DOMAIN_CHROMA_VECTOR_BACKEND=chroma``\n        * ``EVENTS_DEBUG_MODE=false``\n\nIf a requested var is missing, resolution falls back gracefully:\n\n1. ``<LAYER>_<PROVIDER>_<KEY>``\n2. ``<LAYER>_<KEY>``\n3. ``<KEY>``\n4. Provided ``default`` (if any)\n\nBoolean casting accepts common truthy strings: ``1, true, yes, on`` (case-insensitive).\n\"\"\"\n\n\n\nimport logging\nimport os\nfrom typing import Any, Callable, Optional, TypeVar\n\nfrom dotenv import load_dotenv\n\n# --------------------------------------------------------------------------- #\n# Initialisation                                                              #\n# --------------------------------------------------------------------------- #\n\nload_dotenv(override=False)  # never clobber system-exported envs\n_logger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\n\n# Default layer when the caller omits *layer* and ACTIVE_LAYER is unset\nDEFAULT_LAYER: str = os.getenv(\"ACTIVE_LAYER\", \"FASTAPI\").upper()\n\n# --------------------------------------------------------------------------- #\n# Helpers                                                                     #\n# --------------------------------------------------------------------------- #\n\n\ndef _to_bool(raw: str | bool | None) -> bool:\n    \"\"\"Cast an env string to bool with generous truthy values.\"\"\"\n    if isinstance(raw, bool):\n        return raw\n    if raw is None:\n        return False\n    return raw.strip().lower() in {\"1\", \"true\", \"t\", \"yes\", \"y\", \"on\"}\n\n\n_CASTERS: dict[type, Callable[[str], Any]] = {\n    bool: _to_bool,\n    int: int,\n    float: float,\n    str: str,\n}\n\n# --------------------------------------------------------------------------- #\n# Public API                                                                  #\n# --------------------------------------------------------------------------- #\n\n\nclass Config:\n    \"\"\"Callable env-lookup utility.\"\"\"\n\n    def __call__(\n        self,\n        key: str,\n        *,\n        layer: str | None = None,\n        provider: str | None = None,\n        default: Optional[T] = None,\n        cast: type[T] = str,  # type: ignore[assignment]\n    ) -> T | None:\n        \"\"\"Resolve and cast an environment variable.\n\n        Parameters\n        ----------\n        key\n            Core variable name (case-insensitive), e.g. ``\"LLM_MODEL\"``.\n        layer\n            Layer prefix (``FASTAPI``, ``DOMAIN``, â€¦).\n            Defaults to ``DEFAULT_LAYER``.\n        provider\n            Optional provider infix (``AZURE``, ``CHROMA`` â€¦).\n        default\n            Fallback value if the env var is absent *or* cannot be cast.\n        cast\n            Desired return type â€“ one of ``str``, ``int``, ``float``, ``bool``.\n        \"\"\"\n        if cast not in _CASTERS:\n            raise TypeError(\n                f\"Unsupported cast type: {cast!r}. \"\n                f\"Choose from {', '.join(t.__name__ for t in _CASTERS)}.\"\n            )\n\n        parts: list[str] = []\n        if layer := (layer or DEFAULT_LAYER):\n            parts.append(layer.upper())\n        if provider:\n            parts.append(provider.upper())\n        parts.append(key.upper())\n        env_key = \"_\".join(parts)\n\n        val: str | None = os.getenv(env_key)\n\n        # 2ï¸âƒ£ try without provider\n        if val is None and provider:\n            val = os.getenv(f\"{layer}_{key}\".upper())\n\n        # 3ï¸âƒ£ fall back to plain key\n        if val is None:\n            val = os.getenv(key.upper())\n\n        if val is None:\n            return default  # type: ignore[return-value]\n\n        try:\n            return _CASTERS[cast](val)  # type: ignore[return-value]\n        except Exception as exc:  # noqa: BLE001\n            _logger.warning(\n                \"CONFIG: failed to cast %s=%r to %s â€“ %s\",\n                env_key,\n                val,\n                cast.__name__,\n                exc,\n            )\n            return default  # type: ignore[return-value]\n\n\ncfg = Config()\n\n# Convenience wrappers â€“ purely syntactic sugar\nget_bool = lambda k, **kw: cfg(k, cast=bool, **kw)  # noqa: E731\nget_int = lambda k, **kw: cfg(k, cast=int, **kw)  # noqa: E731\nget_float = lambda k, **kw: cfg(k, cast=float, **kw)  # noqa: E731\nget_str = lambda k, **kw: cfg(k, cast=str, **kw)  # noqa: E731\n\n# --------------------------------------------------------------------------- #\n# Quick self-test                                                             #\n# --------------------------------------------------------------------------- #\n\nif __name__ == \"__main__\":  # pragma: no cover\n    logging.basicConfig(level=\"INFO\", format=\"%(levelname)s: %(message)s\")\n\n    print(\"ACTIVE_LAYER:\", DEFAULT_LAYER)\n    print(\"FASTAPI -> DEBUG_MODE (bool):\",\n          cfg(\"DEBUG_MODE\", layer=\"FASTAPI\", cast=bool))\n    print(\"FASTAPI+AZURE -> LLM_MODEL (str):\",\n          cfg(\"LLM_MODEL\", layer=\"FASTAPI\", provider=\"AZURE\"))\n"
  },
  {
    "path": "app/main.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/app/main.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\nimport logging, structlog, os\nfrom pathlib import Path\nfrom typing import Annotated, Any\n\nfrom fastapi import Depends, FastAPI, HTTPException, Request, Response\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import HTMLResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom prometheus_client import Histogram, generate_latest\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom app.config import cfg\n\n# -------- structured logging ---------\nstructlog.configure(\n    wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),\n    processors=[\n        structlog.processors.TimeStamper(fmt=\"iso\"),\n        structlog.processors.JSONRenderer()\n    ],\n)\nlog = structlog.get_logger(\"ai-agent\")\n\n\n\n\n# Optional retrievers (import-guarded so the app can start without them)\ntry:\n    from retrievers.chroma_retriever import ChromaRetriever\nexcept ImportError as exc:\n    ChromaRetriever = None\n    logging.warning(\"Chroma retriever unavailable â€“ %s\", exc)\n\ntry:\n    from retrievers.azure_search_retriever import AzureSearchRetriever\nexcept ImportError as exc:\n    AzureSearchRetriever = None\n    logging.warning(\"Azure Search retriever unavailable â€“ %s\", exc)\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Logging setup\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nlogger = logging.getLogger(\"ai_agent\")\nlogging.basicConfig(\n    level=os.getenv(\"LOG_LEVEL\", \"INFO\"),\n    format=\"%(levelname)s: %(message)s\",\n)\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# FastAPI app + Prometheus metric\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\napp = FastAPI(title=\"AI Building Blocks Agent\", version=\"0.3.0-dev\")\n\n# Global histogram â€“ used by chat route to record end-to-end latency\nrequest_latency = Histogram(\n    \"chat_latency_ms\",\n    \"End-to-end latency of /chat route in milliseconds\",\n)\n\n@app.get(\"/metrics\")\ndef metrics() -> Response:\n    \"\"\"\n    Prometheus scrape endpoint\n    \"\"\"\n    return Response(generate_latest(), media_type=\"text/plain\")\n\n# ---------- OpenTelemetry ------------\nif os.getenv(\"OTEL_EXPORTER_OTLP_ENDPOINT\", \"http://localhost:4317\"):\n    tp = TracerProvider(resource=Resource.create({\"service.name\": \"ai-agent\"}))\n    tp.add_span_processor(\n        BatchSpanProcessor(OTLPSpanExporter())\n    )\n    trace.set_tracer_provider(tp)\n\ntracer = trace.get_tracer(__name__)\n\n# FastAPI / requests auto-instrument\nfrom opentelemetry.instrumentation.fastapi import FastAPIInstrumentor\nfrom opentelemetry.instrumentation.requests import RequestsInstrumentor\n# later, right after `app = FastAPI()`:\nFastAPIInstrumentor().instrument_app(app)\nRequestsInstrumentor().instrument()\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Static & assets\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nPROJECT_ROOT = Path(__file__).resolve().parent.parent\nSTATIC_DIR   = PROJECT_ROOT / \"static\"\nASSETS_DIR   = PROJECT_ROOT / \"app\" / \"assets\"\n\napp.mount(\"/static\", StaticFiles(directory=STATIC_DIR), name=\"static\")\napp.mount(\"/assets\", StaticFiles(directory=ASSETS_DIR), name=\"assets\")\n\n@app.get(\"/\", tags=[\"meta\"], response_class=HTMLResponse)\nasync def root() -> HTMLResponse:\n    \"\"\"\n    Single-page chat UI (opens *static/index.html*).\n    \"\"\"\n    index_path = STATIC_DIR / \"index.html\"\n    if not index_path.exists():\n        return HTMLResponse(\n            \"<h2>index.html not found â€” did you copy the static folder?</h2>\",\n            status_code=404,\n        )\n    return HTMLResponse(index_path.read_text(encoding=\"utf-8\"), status_code=200)\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# CORS\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\norigins = cfg(\"CORS_ORIGINS\", cast=str, default=\"*\") or \"*\"\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[origins] if origins != \"*\" else [\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Startup: choose vector retriever\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n@app.on_event(\"startup\")\nasync def _startup() -> None:\n    layer    = cfg(\"ACTIVE_LAYER\", default=\"FASTAPI\").upper()\n    backend  = cfg(\"VECTOR_BACKEND\", layer=layer,\n                   default=os.getenv(\"FASTAPI_VECTOR_BACKEND\", \"chroma\")).lower()\n    provider = cfg(\"LLM_PROVIDER\", layer=layer,\n                   default=os.getenv(\"FASTAPI_LLM_PROVIDER\", \"azure\"))\n\n    logger.info(\"=== AI-Agent startup ===\")\n    logger.info(\"Layer=%s | VectorBackend=%s | LLM=%s\", layer, backend, provider)\n\n    if backend == \"chroma\":\n        if ChromaRetriever is None:\n            raise RuntimeError(\"chromadb not installed but VECTOR_BACKEND='chroma'.\")\n        app.state.retriever = ChromaRetriever(layer=layer)\n\n    elif backend in {\"azure\", \"azure_search\", \"azsearch\"}:\n        if AzureSearchRetriever is None:\n            raise RuntimeError(\"Azure Search retriever dependencies missing.\")\n        app.state.retriever = AzureSearchRetriever(layer=layer)\n\n    else:\n        logger.warning(\"Unknown VECTOR_BACKEND '%s' â€“ retriever disabled.\", backend)\n        app.state.retriever = None\n\n    # Honour <LAYER>_VECTOR_ENABLED\n    if not cfg(\"VECTOR_ENABLED\", layer=layer, cast=bool, default=True):\n        logger.warning(\"%s: VECTOR layer disabled â€“ using NullRetriever.\", layer)\n        from retrievers.null_retriever import NullRetriever\n        app.state.retriever = NullRetriever()\n        return\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Dependency injection helper\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef get_retriever(request: Request):\n    r = getattr(request.app.state, \"retriever\", None)\n    if r is None:\n        raise HTTPException(404, \"Vector retriever not configured.\")\n    return r\n\nRetrieverDep = Annotated[Any, Depends(get_retriever)]\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Sample utility endpoints\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n@app.get(\"/search\")\nasync def search_endpoint(q: str, retriever: RetrieverDep):\n    if hasattr(retriever, \"query\"):\n        return retriever.query(q, k=5)\n    return {\"error\": \"Retriever does not implement 'query'.\"}\n\n@app.get(\"/health\", tags=[\"meta\"])\nasync def health():\n    return {\"status\": \"ok\", \"layer\": cfg(\"ACTIVE_LAYER\", default=\"FASTAPI\")}\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Routers\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntry:\n    from app.routers import chat_routes          # noqa: WPS433\n    app.include_router(chat_routes.router, prefix=\"/chat\")\nexcept ImportError as exc:\n    logger.warning(\"chat_routes not present â€“ skipping (%s).\", exc)\ntry:\n    from app.routers.meraki_routes import router as meraki_router\n    app.include_router(meraki_router)    # no prefix, since your paths start with /meraki\n    logger.info(\"Mounted Meraki routes\")\nexcept ImportError as exc:\n    logger.warning(\"meraki_routes not present â€“ skipping (%s)\", exc)"
  },
  {
    "path": "app/llm/azure_openai.py",
    "content": "# app/llm/azure_openai.py  (temporary shim)\nfrom app.llm.llm_factory import AzureOpenAIClient\n__all__ = [\"AzureOpenAIClient\"]\n"
  },
  {
    "path": "app/llm/base_llm.py",
    "content": "# app/llm/base_llm.py\nclass BaseLLM:                       # legacy name used by older modules\n    \"\"\"Removed during refactor â€“ kept only for backward-compat.\"\"\"\n    async def chat(self, *a, **kw):   # never called â€“ real work is in llm_factory\n        raise NotImplementedError\n"
  },
  {
    "path": "app/llm/dynamic.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/app/llm/dynamic.py\n## Copyright (c) 2025 Jeff Teeter, Ph.D.\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n \n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n\n\"\"\"\nDynamic helper that chooses the correct vector-search retriever and\nbuilds the diet-function list the LLM receives.\n\n* Never raises AttributeError if a given retriever class name is missing.\n* Supports Chroma, Azure Cognitive Search and Elastic back-ends out-of-the-box.\n* Falls back to the first â€œSomethingRetrieverâ€ class it can find, so adding new\n  back-ends later is zero-touch.\n\nENV VARS\n--------\nFASTAPI_VECTOR_BACKEND          chroma | azure | elastic   (default: chroma)\nFASTAPI_CHROMA_COLLECTION_PLATFORM  override Chroma collection name\n\"\"\"\nimport importlib\nimport inspect\nimport json\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict, List\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 1.  Pick retriever backend\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nBACKEND = os.getenv(\"FASTAPI_VECTOR_BACKEND\", \"chroma\").lower()\n\nRETRIEVER_MODULES: dict[str, str] = {\n    \"chroma\":  \"retrievers.chroma_retriever\",\n    \"azure\":   \"retrievers.azure_search_retriever\",\n    \"elastic\": \"retrievers.elastic_retriever\",\n}\nif BACKEND not in RETRIEVER_MODULES:\n    raise ValueError(\n        f\"Unsupported FASTAPI_VECTOR_BACKEND={BACKEND!r}. \"\n        f\"Expected one of: {', '.join(RETRIEVER_MODULES)}\"\n    )\n\nmod = importlib.import_module(RETRIEVER_MODULES[BACKEND])\n\n# Try the common names first, then fall back to â€œany *Retriever classâ€\nRetriever = (\n    getattr(mod, \"FunctionRetriever\", None)\n    or getattr(mod, \"ChromaRetriever\", None)\n    or getattr(mod, \"AzureSearchRetriever\", None)\n    or getattr(mod, \"ElasticRetriever\", None)\n)\n\nif Retriever is None:\n    for attr in dir(mod):\n        obj = getattr(mod, attr)\n        if inspect.isclass(obj) and attr.endswith(\"Retriever\"):\n            Retriever = obj\n            break\n\nif Retriever is None:  # still nothing?  bail out clearly.\n    raise ImportError(\n        f\"No retriever class found in module {RETRIEVER_MODULES[BACKEND]}\"\n    )\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 2.  Instantiate a singleton\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nif BACKEND == \"chroma\":\n    retriever = Retriever(\n        collection_name=os.getenv(\n            \"FASTAPI_CHROMA_COLLECTION_PLATFORM\",\n            \"platform-summaries-index\",\n        )\n    )\n    # honour dynamic override if the Chroma client exposes helpers\n    custom_col = os.getenv(\n        \"FASTAPI_CHROMA_COLLECTION_PLATFORM\",\n        \"platform-summaries-index\",\n    )\n    if hasattr(retriever, \"set_collection\"):\n        retriever.set_collection(custom_col)\n    elif hasattr(retriever, \"collection_name\"):\n        setattr(retriever, \"collection_name\", custom_col)\nelse:  # Azure / Elastic (both accept layer kwarg)\n    retriever = Retriever(layer=\"FASTAPI\")\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 3.  Full-schema KV (lazy build + cache)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nDYNAMIC_CACHE_ROOT = Path(\n    os.getenv(\n        \"PLATFORM_DYNAMIC_CACHE_PATH\",\n        # Default: <repo-root>/ai-building-blocks-agent/app/platform_dynamic_cache\n        (Path(__file__).resolve().parent.parent / \"platform_dynamic_cache\").as_posix(),\n    )\n).resolve()\nDYNAMIC_CACHE_ROOT.mkdir(parents=True, exist_ok=True)\n\nCACHE_FILE = DYNAMIC_CACHE_ROOT / \"full_schemas.json\"\nSPEC_DIR   = Path(__file__).resolve().parent / \"openapi_specs\"\n\n\ndef _build_full_kv() -> Dict[str, Any]:\n    \"\"\"Load `openapi_specs/full_*.json` files into a single lookup table.\"\"\"\n    kv: dict[str, Any] = {}\n    for fp in SPEC_DIR.glob(\"full_*.json\"):\n        platform = fp.stem.replace(\"full_\", \"\")\n        spec     = json.loads(fp.read_text(encoding=\"utf-8\"))\n        for path_item in spec.get(\"paths\", {}).values():\n            for op in path_item.values():\n                op_id = op.get(\"operationId\")\n                if op_id:\n                    kv[f\"{platform}:{op_id}\"] = op\n    CACHE_FILE.write_text(json.dumps(kv), encoding=\"utf-8\")\n    return kv\n\n\nFULL_KV: Dict[str, Any] = (\n    json.loads(CACHE_FILE.read_text(encoding=\"utf-8\"))\n    if CACHE_FILE.exists()\n    else _build_full_kv()\n)\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# 4.  Public helpers\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef build_functions_for_llm(\n    query: str,\n    enabled: list[str],\n    *,\n    token_budget: int = int(os.getenv(\"FASTAPI_FUNCTION_TOKEN_BUDGET\", 16_384)),\n    k: int = int(os.getenv(\"FASTAPI_FUNCTION_TOP_K\", 50)),\n \n) -> List[dict]:\n    \"\"\"\n    Return a list of diet-function JSON objects that the LLM will receive.\n\n    1. Top-k vector search over enabled platforms.\n    2. Lexical fallback: include any function whose *name* contains a user token\n       (case-insensitive, pluralâ‡¢singular). Lexical hits are prepended so they\n       always survive trimming.\n    3. Trim JSON payload to fit within *token_budget*.\n    \"\"\"\n    # â”€â”€ 1. vector search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    vec_hits: list[dict] = retriever.query(\n        query,\n        k=k,\n        filter={\"platform\": {\"$in\": enabled}},\n    )\n    have: set[str] = {d[\"name\"] for d in vec_hits}\n\n    # â”€â”€ 2. lexical fallback  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    raw_tokens = [t.lower().strip(\".,!?\") for t in query.split()]\n    tokens: set[str] = set()\n    for tok in raw_tokens:\n        tokens.add(tok)\n        if tok.endswith(\"s\") and len(tok) > 3:\n            tokens.add(tok[:-1])\n\n    lex_hits: list[dict] = []\n    for platform in enabled:\n        every = retriever.query(\n            \"\",                  # empty query returns everything\n            k=200,               # ğŸ”¥ lowered from 1000 â†’ 200\n            filter={\"platform\": {\"$in\": [platform]}},\n        )\n        for d in every:\n            if d[\"name\"] in have:\n                continue\n            if any(tok in d[\"name\"].lower() for tok in tokens):\n                lex_hits.append(d)\n                have.add(d[\"name\"])\n\n    # lexical hits *first* â†’ they survive trimming\n    docs = lex_hits + vec_hits\n\n    # â”€â”€ 3. unwrap  + schema-sanity  + trimming â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    size = 0\n    out: list[dict] = []\n\n    for d in docs:\n        try:\n            fn_schema = json.loads(d[\"content\"])\n        except (KeyError, json.JSONDecodeError):\n            continue\n\n        # fix OpenAI array-schema quirk (missing \"items\")\n        for pschema in fn_schema.get(\"parameters\", {}).get(\"properties\", {}).values():\n            if pschema.get(\"type\") == \"array\" and \"items\" not in pschema:\n                pschema[\"items\"] = {\"type\": \"string\"}\n\n        payload = json.dumps(fn_schema, separators=(\",\", \":\"))\n        if size + len(payload) > token_budget:\n            break\n\n        size += len(payload)\n        out.append(fn_schema)\n\n    return out\n\n\ndef full_schema_lookup(platform: str, name: str) -> dict | None:\n    \"\"\"Return the full OpenAPI operation object (or `None` if not found).\"\"\"\n    return FULL_KV.get(f\"{platform}:{name}\")\n\n"
  },
  {
    "path": "app/llm/llm_factory.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/app/llm/llm_factory.py\n## Copyright (c) 2025 Jeff Teeter, Ph.D.\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n \n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\nimport asyncio\nimport json\nimport logging\nimport os\nimport sys\nimport typing\nfrom functools import partial\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Literal, Optional, Union\nimport aiohttp\nimport openai\nfrom app.config import cfg\n\n\"\"\"LLM Factory â€“ async wrapper over multiple backâ€‘ends.\n\nSupported providers (pick via `<LAYER>_LLM_PROVIDER`):\n----------------------------------------------------\n* **azure**   â€“ Azure OpenAI Chat Completions\n* **openai**  â€“ Public OpenAI API\n* **llama3**  â€“ Ollamaâ€‘style `/api/generate` (or any HTTP that follows that schema)\n* **hf_local** â€“ Onâ€‘prem model via *transformers* **or** *llamaâ€‘cppâ€‘python* (CPUâ€‘friendly)\n* **tgi** / **vllm** â€“ Generic OpenAIâ€‘compatible REST service (HuggingFace TGI 1.4+, vLLM â‰¥0.4)\n\nEach client exposes `await chat(messages, **kwargs) -> str` where\n`messages = [{\"role\": \"user\"|\"assistant\"|\"system\", \"content\": \"...\"}]`.\n\"\"\"\nlogger = logging.getLogger(__name__)\n\n# ---------------------------------------------------------------------------\n# Base interface\n# ---------------------------------------------------------------------------\nclass LLMClientBase:\n    async def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:  # noqa: D401\n        raise NotImplementedError\n\n\n# ---------------------------------------------------------------------------\n# Azure OpenAI\n# ---------------------------------------------------------------------------\nclass AzureOpenAIClient(LLMClientBase):\n    def __init__(self, *, layer: str):\n        self.deployment   = cfg(\"OPENAI_MODEL\",    layer=layer, provider=\"AZURE\")\n        self.endpoint     = cfg(\"OPENAI_ENDPOINT\", layer=layer, provider=\"AZURE\")\n        self.api_key      = cfg(\"OPENAI_KEY\",      layer=layer, provider=\"AZURE\")\n        self.api_version  = cfg(\"OPENAI_API_VERSION\",\n                                layer=layer, provider=\"AZURE\", default=\"2023-05-15\")\n\n        if not all((self.deployment, self.endpoint, self.api_key)):\n            raise ValueError(\"Azure OpenAI credentials incomplete.\")\n        openai.api_type    = \"azure\"\n        openai.api_base    = self.endpoint\n        openai.api_version = self.api_version\n        openai.api_key     = self.api_key\n\n    # NEW implementation â”€ keeps the whole dict when a function call is returned\n    async def chat(\n        self,\n        messages: List[Dict[str, str]],\n        **kwargs,\n) -> Union[str, Dict[str, Any]]:       # <-- use Union from typing\n\n \n        \"\"\"\n        â€¢ If the model answers with plain text â†’ return that string.  \n        â€¢ If the model decides to call a function â†’ return the *entire*\n          message dict so `function_call` is preserved.\n        \"\"\"\n        resp = await openai.ChatCompletion.acreate(\n            deployment_id=self.deployment,\n            messages=messages,\n            **kwargs,\n        )\n        msg = resp.choices[0].message.to_dict()\n        return msg if msg.get(\"function_call\") else msg.get(\"content\", \"\")\n    \n# ---------------------------------------------------------------------------\n# Public OpenAI\n# ---------------------------------------------------------------------------\nclass OpenAIClient(LLMClientBase):\n    def __init__(self, *, layer: str):\n        self.api_key = cfg(\"OPENAI_API_KEY\", layer=layer)\n        self.model = cfg(\"OPENAI_MODEL\", layer=layer, default=\"gpt-4o-mini\")\n        if not self.api_key:\n            raise ValueError(\"OPENAI_API_KEY missing\")\n        openai.api_key = self.api_key\n\n    async def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:  # noqa: D401\n        resp = await openai.ChatCompletion.acreate(model=self.model, messages=messages, **kwargs)  # type: ignore[attr-defined]\n        return resp.choices[0].message.content\n\n\n# ---------------------------------------------------------------------------\n# Llama 3 via simple generate endpoint (e.g. Ollama)\n# ---------------------------------------------------------------------------\nclass Llama3Client(LLMClientBase):\n    def __init__(self, *, layer: str):\n        self.base_url = cfg(\"LLAMA3_BASE_URL\", layer=layer, default=\"http://localhost:11434\")\n        self.model = cfg(\"LLAMA3_MODEL_NAME\", layer=layer, default=\"llama3\")\n\n    async def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:  # noqa: D401\n        prompt = \"\\n\".join([m[\"content\"] for m in messages])\n        async with aiohttp.ClientSession() as sess:\n            async with sess.post(f\"{self.base_url}/api/generate\", json={\"model\": self.model, \"prompt\": prompt, **kwargs}, timeout=60) as resp:\n                resp.raise_for_status()\n                data = await resp.json()\n                return data[\"response\"]\n\n\n# ---------------------------------------------------------------------------\n# HFâ€‘Local (transformers *or* llamaâ€‘cppâ€‘python)\n# ---------------------------------------------------------------------------\nclass HFLocalClient(LLMClientBase):\n    \"\"\"Runs a model inâ€‘process â€“ good for CPUâ€‘only boxes.\"\"\"\n\n    def __init__(self, *, layer: str):\n        self.engine = cfg(\"HF_LOCAL_ENGINE\", layer=layer, default=\"transformers\").lower()\n        self.model_path = cfg(\"HF_LOCAL_MODEL_PATH\", layer=layer)  # local .gguf or HF model id\n        self.model_name = cfg(\"HF_LOCAL_MODEL_NAME\", layer=layer, default=\"mistralai/Mistral-7B-Instruct-v0.2\")\n        self.max_new = cfg(\"HF_LOCAL_MAX_TOKENS\", layer=layer, cast=int, default=256)\n\n        if self.engine == \"transformers\":\n            try:\n                from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline  # type: ignore\n            except ImportError:\n                raise ImportError(\"transformers not installed â€“ pip install transformers sentencepiece\")\n            model_id = self.model_path or self.model_name\n            logger.info(\"Loading transformers model %s (this may take a while)â€¦\", model_id)\n            tok = AutoTokenizer.from_pretrained(model_id)\n            mod = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", trust_remote_code=True)\n            self.pipe = pipeline(\"text-generation\", model=mod, tokenizer=tok)\n        elif self.engine == \"llama_cpp\":\n            try:\n                from llama_cpp import Llama  # type: ignore\n            except ImportError:\n                raise ImportError(\"llama-cpp-python not installed â€“ pip install llama-cpp-python\")\n            gguf_path = Path(self.model_path or \"./model.gguf\")\n            if not gguf_path.exists():\n                raise FileNotFoundError(f\"GGUF model not found at {gguf_path}\")\n            self.llm = Llama(model_path=str(gguf_path), n_ctx=4096)\n        else:\n            raise ValueError(f\"Unknown HF_LOCAL_ENGINE '{self.engine}' (transformers | llama_cpp)\")\n\n    async def _run_blocking(self, prompt: str) -> str:\n        if self.engine == \"transformers\":\n            res = self.pipe(prompt, max_new_tokens=self.max_new, do_sample=True)\n            return res[0][\"generated_text\"][len(prompt) :].strip()\n        else:  # llama_cpp\n            res = self.llm.create_chat_completion(messages=[{\"role\": \"user\", \"content\": prompt}], max_tokens=self.max_new)\n            return res[\"choices\"][0][\"message\"][\"content\"].strip()\n\n    async def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:  # noqa: D401\n        prompt = \"\\n\".join([m[\"content\"] for m in messages])\n        loop = asyncio.get_running_loop()\n        return await loop.run_in_executor(None, partial(self._run_blocking, prompt))\n\n\n# ---------------------------------------------------------------------------\n# TGI / vLLM remote server (OpenAI compatible)\n# ---------------------------------------------------------------------------\nclass TGIClient(LLMClientBase):\n    def __init__(self, *, layer: str):\n        self.base_url = cfg(\"TGI_BASE_URL\", layer=layer, default=\"http://localhost:8000\")\n        self.model = cfg(\"TGI_MODEL_NAME\", layer=layer, default=\"local-model\")\n        self.timeout = cfg(\"TGI_TIMEOUT_S\", layer=layer, cast=int, default=60)\n\n    async def chat(self, messages: List[Dict[str, str]], **kwargs) -> str:  # noqa: D401\n        payload = {\"model\": self.model, \"messages\": messages, **kwargs}\n        async with aiohttp.ClientSession() as sess:\n            async with sess.post(f\"{self.base_url}/v1/chat/completions\", json=payload, timeout=self.timeout) as resp:\n                resp.raise_for_status()\n                data = await resp.json()\n                return data[\"choices\"][0][\"message\"][\"content\"].strip()\n\n\n# ---------------------------------------------------------------------------\n# Factory\n# ---------------------------------------------------------------------------\nProviderType = Literal[\"azure\", \"openai\", \"llama3\", \"hf_local\", \"tgi\", \"vllm\"]\n\n\ndef get_llm(layer: str | None = None) -> LLMClientBase:  # noqa: D401\n    layer = (layer or cfg(\"ACTIVE_LAYER\", default=\"FASTAPI\")).upper()\n    provider: ProviderType = cfg(\"LLM_PROVIDER\", layer=layer, default=\"azure\").lower()  # type: ignore[assignment]\n    logger.info(\"LLM factory â€“ layer=%s provider=%s\", layer, provider)\n    # Bail out early if the layer says \"no LLM\"\n\n    if not cfg(\"LLM_ENABLED\", layer=layer, cast=bool, default=True):\n        class _Dummy(LLMClientBase):\n            async def chat(self, messages, **kw):      # noqa: D401\n                return \"âš ï¸  LLM disabled for this layer.\"\n        return _Dummy()\n\n    if provider == \"azure\":\n        return AzureOpenAIClient(layer=layer)\n    if provider == \"openai\":\n        return OpenAIClient(layer=layer)\n    if provider == \"llama3\":\n        return Llama3Client(layer=layer)\n    if provider == \"hf_local\":\n        return HFLocalClient(layer=layer)\n    if provider in {\"tgi\", \"vllm\"}:\n        return TGIClient(layer=layer)\n\n    raise ValueError(f\"Unsupported LLM provider '{provider}'.\")\n\n\n__all__ = [\n    \"LLMClientBase\",\n    \"AzureOpenAIClient\",\n    \"OpenAIClient\",\n    \"Llama3Client\",\n    \"HFLocalClient\",\n    \"TGIClient\",\n    \"get_llm\",\n]\n"
  },
  {
    "path": "app/llm/prompt_templates.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/app/llm/prompt_templates.py\n## Copyright (c) 2025 Jeff Teeter, Ph.D.\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\n# Example prompt templates for the LLM\n# Adjust these as needed for your domain and instructions.\n\nBASE_SYSTEM_PROMPT_DOCS_ONLY = \"\"\"You are a helpful AI assistant. You must only use the provided documents to answer questions.\n\n1. If the answer is not in the documents, say \"I don't know.\" Do not use any external knowledge.\n2. Return answers in HTML format only (no triple backticks).\n3. If the user's message is clearly continuing a previous request (e.g., \"yes\", \"please proceed\", \"go ahead\"), \n   and you have already suggested a function call or next step, do not say \"I don't know.\" \n   Instead, proceed with the indicated function or next step (i.e., multi-turn continuation).\n\"\"\"\n\nBASE_SYSTEM_PROMPT_GENERAL = \"\"\"You are a helpful AI assistant. You can use your own knowledge to answer questions if no documents are provided.\"\"\"\n\nBASE_SYSTEM_PROMPT_EVENT = \"\"\"\nYou are an AI assistant specialized in explaining Cisco event data.\nYou must only use the provided event documents to answer questions.\n\nWhen the user requests event details, display them in a well-structured HTML format as follows:\n1. Please output pure HTML without wrapping it in Markdown fences (no triple backticks).\n2. Always show the <strong>Event ID</strong>, <strong>Detected event</strong>, <strong>Zone</strong>, \n   <strong>Date/Time</strong>, <strong>Camera</strong>, <strong>Building</strong>, <strong>Floor</strong>, \n   and <strong>Location</strong>.\n3. If 'recommended_actions' are present, list them under a <strong>Recommended Actions</strong> heading \n   with <ul> and <li>.\n4. If 'urls_for_further_action' are present, display them as clickable links under a \n   <strong>Additional URLs</strong> heading. Each link should be configured to open in a new browser\n   window (or tab) in fullscreen or 100% mode. For example:\n   <a href=\"LINK_URL\"\n      target=\"_blank\" \n      onclick=\"window.open('LINK_URL','_blank','fullscreen=yes'); return false;\">\n      LINK_NAME\n   </a>\n5. If 'extra_notes' are present, display them under a <strong>Notes</strong> heading in bullet points.\n6. Make the layout easy to read: separate major sections with <hr> or <p>.\n7. If the information is not in the documents, say \"I don't know.\"\n8. Do not wrap any output in code fences, and do not use triple backticks. All content must be valid HTML.  \n\"\"\"\n\nBASE_SYSTEM_PROMPT_LOB = \"\"\"\nYou are an AI assistant specialized in explaining LOB (healthcare) data.\nYou must only use the provided LOB documents to answer questions.\n\nWhen responding:\n1. Please output pure HTML without wrapping it in Markdown fences (no triple backticks).\n2. If the user requests a summary or data, display it in a well-structured HTML format \n   such as a table or list. \n3. If the user specifically asks to draft an email or letter, create a concise, \n   professional email (or letter) with these elements:\n   - **Subject** (for email)\n   - **Greeting** (e.g., \"Dear Alice Johnson,\" or \"Hello Bob,\")\n   - **Body** with relevant details (appointments, instructions, etc.)\n   - **Closing**, like \"Best regards,\" and a signature line\n   - If relevant data (like appointment times, reasons, or instructions) is found in \n     your provided LOB documents, incorporate it. If not, say \"I don't know.\"\n4. If the question asks for other details not in the documents, respond with \"I don't know.\"\n5. Make sure the final output is pure HTMLâ€”no Markdown code fences or triple backticks.\n\n\"\"\"\n\nHTML_MERAKI_INVENTORY_PROMPT = \"\"\"\nYou just called a Cisco function (Meraki) and have JSON with devices in the organization's inventory.\nPlease parse each device object and display the following fields (if available) in an HTML table:\n\n- <strong>Serial</strong>\n- <strong>MAC</strong>\n- <strong>Name</strong>\n- <strong>Model</strong>\n- <strong>Network ID</strong>\n- <strong>Product Type</strong>\n- <strong>Claimed At</strong>\n- <strong>License Expiration Date</strong>\n- <strong>Tags</strong>\n- <strong>Country Code</strong>\n\n**Requirements**:\n1. Only output valid HTML (no Markdown fences). \n2. Use a simple `<table>` with `<thead>` and `<tbody>`.\n3. Each device = one row. \n4. If a field is missing, leave it blank.\n5. Make it look professional and easy to read.\n6. Do NOT provide any other summary or explanation text, just the HTML table.\n\"\"\"\nHTML_MERAKI_APS_WITH_MESSAGE_PROMPT = \"\"\"\nYou just called a Cisco function that returned JSON with two keys: \n'message' (a short status string) and 'access_points' (an array of devices).\n\nPlease produce valid HTML:\n1. Display 'message' in an HTML paragraph: <p>{{message}}</p>\n2. Below that, build an HTML table for the 'access_points' array with columns:\n   - <strong>Serial</strong>\n   - <strong>Model</strong>\n   - <strong>MAC</strong>\n   - <strong>Network ID</strong>\n   - <strong>Product Type</strong>\n   - etc. (any relevant fields)\n3. No Markdown backticks or code fences; pure HTML only.\n4. If a field is missing for a device, leave it blank.\n5. No extra commentary or summaryâ€”just the HTML.\n\"\"\"\n\nFUNCTIONS_LLM_PROMPT = \"\"\"\nYou are a meta-assistant that must pick exactly **one** function from the\nJSON list below to satisfy the userâ€™s request.\n\nReturn **only** a JSON object on a single line, with this shape:\n\n{\n  \"name\": \"<function name>\",\n  \"arguments\": { ... }\n}\n\nImportant rules:\nâ€¢ Do NOT wrap the JSON in markdown fences.\nâ€¢ Do NOT add any extra keys or text.\nâ€¢ If no function is relevant, respond with ordinary text instead.\n\"\"\"\n\n\nUSER_PROMPT_TEMPLATE = \"\"\"User: {user_query}\"\"\""
  },
  {
    "path": "app/llm/utils.py",
    "content": "#!/usr/bin/env python3\n# ./ai-building-blocks-agent/app/llm/utils.py\nfrom __future__ import annotations\nimport os\n\n# Map the suffix in ENABLE_<SUFFIX> to the slug used by your scaffolder/json files\n_ALIAS = {\n    \"CATALYST_CENTER\"     : \"catalyst_center\",\n    \"CATALYST_SD_WAN\"     : \"catalyst_sd_wan\",\n    \"CISCO_SPACES\"        : \"spaces\",\n    \"CISCO_WEBEX\"         : \"webex\",\n    \"MERAKI\"              : \"meraki\",\n    \"NEXUS_HYPERFABRIC\"   : \"nexus_hyperfabric\",\n    # add new platforms here â¬†\n}\n\ndef enabled_platforms() -> list[str]:\n    \"\"\"\n    Scan env for ENABLE_<PLATFORM>=true and return a list of platform slugs.\n    Falls back to ['meraki'] if none are set.\n    \"\"\"\n    out: list[str] = []\n    for env_key, value in os.environ.items():\n        if not env_key.startswith(\"ENABLE_\"):\n            continue\n        if value.strip().lower() != \"true\":\n            continue\n        suffix = env_key[len(\"ENABLE_\"):]\n        slug   = _ALIAS.get(suffix, suffix.lower())\n        out.append(slug)\n    return out or [\"meraki\"]      # sensible default\n"
  },
  {
    "path": "retrievers/__init__.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/retrievers/__init__.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n \n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n\nfrom app.config import cfg\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 1ï¸âƒ£  Helper that every retriever can safely import\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\ndef default_pool_size(layer: str, backend: str, *, fallback: int = 4) -> int:\n    \"\"\"\n    Resolution order (highest-to-lowest):\n\n        <LAYER>_<BACKEND>_RETRIEVER_WORKERS\n        <LAYER>_RETRIEVER_WORKERS\n        RETRIEVER_WORKERS\n        fallback (default 4)\n    \"\"\"\n    layer_uc   = layer.upper()\n    backend_uc = backend.upper()\n\n    # first: layer+backend specific\n    val = cfg(f\"{backend_uc}_RETRIEVER_WORKERS\", layer=layer_uc, cast=int, default=None)\n    if val is not None:\n        return val\n\n    # second: layer-wide\n    val = cfg(\"RETRIEVER_WORKERS\", layer=layer_uc, cast=int, default=None)\n    if val is not None:\n        return val\n\n    # third: global\n    val = cfg(\"RETRIEVER_WORKERS\", cast=int, default=fallback)\n    return val\n\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 2ï¸âƒ£  Now import the retriever implementations\n#     (they are free to `from retrievers import default_pool_size`)\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfrom .azure_search_retriever import AzureSearchRetriever   # noqa: E402\nfrom .chroma_retriever       import ChromaRetriever        # noqa: E402\nfrom .elastic_retriever      import ElasticRetriever       # noqa: E402\nfrom .null_retriever         import NullRetriever          # noqa: E402\n\n\n__all__ = [\n    \"default_pool_size\",\n    \"AzureSearchRetriever\",\n    \"ChromaRetriever\",\n    \"ElasticRetriever\",\n    \"NullRetriever\",\n]"
  },
  {
    "path": "retrievers/azure_search_retriever.py",
    "content": "#! /usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n# ai-building-blocks-agent/retrievers/azure_search_retriever.py\n# Copyright (c) 2025 Jeff Teeter, Ph.D. â€“ Cisco Systems, Inc.\n# Apache-2.0  (see LICENSE) â€“ Provided â€œAS ISâ€, no warranties.\n################################################################################\n\"\"\"\nDomain-first retriever for **Azure AI Search** (formerly Cognitive Search).\n\nEnvironment variables (layer-aware â€“ replace <LAYER> with FASTAPI / DOMAIN / â€¦):\n\n    <LAYER>_AZURE_ENDPOINT             https://<svc>.search.windows.net\n    <LAYER>_AZURE_KEY                  <admin-key-or-query-key>\n    <LAYER>_AZURE_API_VERSION          2024-11-01-preview  (default)\n\n    # Index names\n    <LAYER>_AZURE_DOMAIN_INDEX         domain-index            (required)\n    <LAYER>_AZURE_PLATFORM_INDEX       platform-summaries-index\n    <LAYER>_AZURE_API_DOCS_INDEX       api-docs-index\n    <LAYER>_AZURE_EVENTS_INDEX         events-index\n\n    # Embedding creds (Azure OpenAI)\n    <LAYER>_AZURE_OPENAI_ENDPOINT\n    <LAYER>_AZURE_OPENAI_KEY\n    <LAYER>_AZURE_OPENAI_EMBEDDING_DEPLOYMENT\n\"\"\"\n\nimport logging\nimport re\nfrom typing import Dict, List, Optional\n\nimport requests\n\nfrom app.config import cfg\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom retrievers import default_pool_size \n_logger = logging.getLogger(__name__)\n\n\ndef _sanitize_filename(text: str, max_len: int = 100) -> str:  # noqa: D401\n    \"\"\"Remove nasty chars so Windows/macOS donâ€™t choke if files ever get saved.\"\"\"\n    return re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", text)[:max_len].rstrip()\n\n\nclass AzureSearchRetriever:\n    \"\"\"Lightweight wrapper around the *vector + semantic* hybrid query API.\"\"\"\n\n    def __init__(self, *, layer: str | None = None, top_k: int | None = None):\n        self.layer = (layer or cfg(\"ACTIVE_LAYER\", default=\"FASTAPI\")).upper()\n\n        # ------------------------------------------------------------------ #\n        # Connection & auth\n        # ------------------------------------------------------------------ #\n        self.search_endpoint = cfg(\"AZURE_ENDPOINT\", layer=self.layer)\n        self.search_key = cfg(\"AZURE_KEY\", layer=self.layer)\n        self.api_version = cfg(\n            \"AZURE_API_VERSION\", layer=self.layer, default=\"2024-11-01-preview\"\n        )\n\n        if not (self.search_endpoint and self.search_key):\n            raise RuntimeError(\n                f\"[{self.layer}] Missing AZURE_ENDPOINT or AZURE_KEY â€“ check your .env\"\n            )\n\n        # ------------------------------------------------------------------ #\n        # Index names\n        # ------------------------------------------------------------------ #\n        self.domain_index = cfg(\n            \"AZURE_DOMAIN_INDEX\", layer=self.layer, default=\"domain-index\"\n        )\n        self.platform_summaries_index = cfg(\n            \"AZURE_PLATFORM_INDEX\", layer=self.layer, default=\"\"\n        )\n        self.api_docs_index = cfg(\"AZURE_API_DOCS_INDEX\", layer=self.layer, default=\"\")\n        self.events_index = cfg(\"AZURE_EVENTS_INDEX\", layer=self.layer, default=\"\")\n\n        # ------------------------------------------------------------------ #\n        # Embedding (Azure OpenAI)\n        # ------------------------------------------------------------------ #\n        self.openai_endpoint = cfg(\"AZURE_OPENAI_ENDPOINT\", layer=self.layer)\n        self.openai_key = cfg(\"AZURE_OPENAI_KEY\", layer=self.layer)\n        self.embedding_deployment = cfg(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", layer=self.layer)\n        self.openai_api_version = cfg(\n            \"AZURE_OPENAI_API_VERSION\", layer=self.layer, default=\"2023-05-15\"\n        )\n\n        if not all((self.openai_endpoint, self.openai_key, self.embedding_deployment)):\n            raise RuntimeError(\n                f\"[{self.layer}] Missing Azure OpenAI embedding creds â€“ \"\n                \"AZURE_OPENAI_ENDPOINT / AZURE_OPENAI_KEY / AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"\n            )\n\n        # Misc\n        self.vector_field = cfg(\n            \"AZURE_VECTOR_COLUMNS\", layer=self.layer, default=\"embedding\"\n        )\n        self.top_k = int(\n            top_k\n            if top_k is not None\n            else cfg(\"AZURE_TOP_K\", layer=self.layer, cast=int, default=5)\n        )\n        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ concurrent-embed pool size â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n        self.pool_size = default_pool_size(self.layer, \"azure\", fallback=4)\n        # One informative line at construction time\n        print(\n            f\"[{self.layer}/AzureRetriever]  âš™  embed-workers = {self.pool_size}\",\n            flush=True,\n        )\n\n    # ------------------------------------------------------------------ #\n    # Internal helpers\n    # ------------------------------------------------------------------ #\n    def _embed(self, text: str) -> List[float]:\n        body = {\n            \"input\": text,                 # single string is fine\n            \"encoding_format\": \"float\",    # <-- THE important line\n            # \"dimensions\": 1536           # only if you want to shorten vectors\n    }\n        url = (\n            f\"{self.openai_endpoint}/openai/deployments/\"\n            f\"{self.embedding_deployment}/embeddings\"\n            f\"?api-version={self.openai_api_version}\"\n        )\n        resp = requests.post(\n            url,\n            headers={\"api-key\": self.openai_key, \"Content-Type\": \"application/json\"},\n            json=body,\n            timeout=30,\n        )\n        if resp.status_code >= 400:\n            print(\"Azure returned:\", resp.text)   \n        resp.raise_for_status()\n        return resp.json()[\"data\"][0][\"embedding\"]\n\n    def _query(self, index: str, payload: Dict) -> List[Dict]:\n        url = (\n            f\"{self.search_endpoint}/indexes('{index}')/docs/search\"\n            f\"?api-version={self.api_version}\"\n        )\n        try:\n            resp = requests.post(\n                url,\n                headers={\"api-key\": self.search_key, \"Content-Type\": \"application/json\"},\n                json=payload,\n                timeout=60,\n            )\n            resp.raise_for_status()\n            return resp.json().get(\"value\", [])\n        except requests.RequestException as exc:  # noqa: BLE001\n            _logger.error(\"Azure AI Search error on %s â†’ %s\", index, exc)\n            if exc.response is not None:\n                _logger.error(\"Response text: %s\", exc.response.text)\n            return []\n        \n    def _embed_many(self, queries: list[str]) -> list[list[float]]:\n        \"\"\"\n        Parallel embeds with `self.pool_size` workers.\n        \"\"\"\n        with ThreadPoolExecutor(max_workers=self.pool_size) as pool:\n            futs = {pool.submit(self._embed, q): i for i, q in enumerate(queries)}\n            vecs = [None] * len(queries)                         # pre-allocate\n            for fut in as_completed(futs):\n                vecs[futs[fut]] = fut.result()\n        return vecs\n\n    # ------------------------------------------------------------------ #\n    # Public retrieval methods\n    # ------------------------------------------------------------------ #\n    def retrieve_domain_info(self, query: str) -> List[Dict]:\n        vec = self._embed(query)\n        payload = {\n            \"search\": query,\n            \"queryType\": \"semantic\",\n            \"semanticConfiguration\": \"domain-index-semantic-config\",\n            \"top\": self.top_k,\n            \"vectorQueries\": [\n                {\n                    \"kind\": \"vector\",\n                    \"fields\": self.vector_field,\n                    \"vector\": vec,\n                    \"k\": self.top_k,\n                }\n            ],\n            \"select\": \"id,content,metadata\",\n        }\n        return self._query(self.domain_index, payload)\n\n    def retrieve_platform_summaries(self, query: str) -> List[Dict]:\n        \"\"\"\n        Search the *function-definitions* index.  Behaviour can be tuned with\n        two env-vars:\n\n        â€¢ FASTAPI_AZURE_PLATFORM_SEMCONF   Â» name of the semantic-config\n          (set it **empty** to disable semantic ranking).\n        â€¢ FASTAPI_AZURE_PLATFORM_SELECT    Â» comma-sep list of fields to return\n          (must exist in the index doc-schema).\n        \"\"\"\n        if not self.platform_summaries_index:\n            return []\n\n        semconf = cfg(\n            \"AZURE_PLATFORM_SEMCONF\",\n            layer=self.layer,\n            default=\"platform-summaries-semantic-config\",\n        )\n        select = cfg(\n            \"AZURE_PLATFORM_SELECT\",\n            layer=self.layer,\n            default=\"platform,name,content\",     # no doc_type by default\n        )\n\n        vec = self._embed(query)\n        payload: Dict = {\n            \"search\": query,\n            \"top\": self.top_k,\n            \"vectorQueries\": [\n                {\n                    \"kind\": \"vector\",\n                    \"fields\": self.vector_field,\n                    \"vector\": vec,\n                    \"k\": self.top_k,\n                }\n            ],\n            \"select\": select,\n        }\n        if semconf:\n            payload.update(\n                {\n                    \"queryType\": \"semantic\",\n                    \"semanticConfiguration\": semconf,\n                }\n            )\n\n        return self._query(self.platform_summaries_index, payload)\n\n\n \n\n    def retrieve_api_docs(self, query: str, platforms: Optional[List[str]] = None) -> List[Dict]:\n        if not self.api_docs_index:\n            return []\n        vec = self._embed(query)\n        payload = {\n            \"search\": query,\n            \"queryType\": \"semantic\",\n            \"semanticConfiguration\": \"api-docs-semantic-config\",\n            \"top\": self.top_k,\n            \"vectorQueries\": [\n                {\n                    \"kind\": \"vector\",\n                    \"fields\": self.vector_field,\n                    \"vector\": vec,\n                    \"k\": self.top_k,\n                }\n            ],\n            \"select\": \"title,content,platform,doc_type\",\n        }\n        if platforms:\n            payload[\"filter\"] = \" or \".join([f\"platform eq '{p}'\" for p in platforms])\n        return self._query(self.api_docs_index, payload)\n\n    def retrieve_event_info(self, query: str, event_type: Optional[str] = None) -> List[Dict]:\n        if not self.events_index:\n            return []\n        vec = self._embed(query)\n        payload = {\n            \"search\": query,\n            \"queryType\": \"semantic\",\n            \"semanticConfiguration\": \"events-semantic-config\",\n            \"top\": self.top_k,\n            \"vectorQueries\": [\n                {\n                    \"kind\": \"vector\",\n                    \"fields\": self.vector_field,\n                    \"vector\": vec,\n                    \"k\": self.top_k,\n                }\n            ],\n            \"select\": \"event_id,event_name,event_type,content,additional_info\",\n        }\n        if event_type:\n            payload[\"filter\"] = f\"event_type eq '{event_type}'\"\n        return self._query(self.events_index, payload)\n\n \n    # ------------------------------------------------------------------ #\n    # Generic vector query â€“ API-compatible with ChromaRetriever\n    # ------------------------------------------------------------------ #\n    def query(\n        self,\n        text: str,\n        *,\n        k: int = 128,\n        filter: Optional[dict] = None,\n    ) -> List[Dict]:\n        \"\"\"\n        Wrapper used by dynamic.build_functions_for_llm().\n        Just redirect to the trusted retrieve_platform_summaries().\n        \"\"\"\n        # honour the simple platform filter, if present\n        if filter and \"platform\" in filter:\n            clause = filter[\"platform\"]\n            if isinstance(clause, dict) and \"$in\" in clause:\n                platforms = clause[\"$in\"]\n                if platforms and self.platform_summaries_index:\n                    # form Azure $filter clause\n                    self._extra_filter = \" or \".join(\n                        [f\"platform eq '{p}'\" for p in platforms]\n                    )\n        else:\n            self._extra_filter = None\n\n        # call the original method (it already embeds + does semantic search)\n        hits = self.retrieve_platform_summaries(text)\n\n        # keep only top-k (retrieve_platform_summaries already uses self.top_k,\n        # but dynamic.py may pass k < self.top_k)\n        return hits[:k]"
  },
  {
    "path": "retrievers/chroma_retriever.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/retrievers/chroma_retriever.py\n## Copyright (c) 2025 Jeff Teeter, Ph.D.\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\"\"\"\nVery thin wrapper around a *single* Chroma collection.\n\nâ€¢ query(text, k)               â€“ generic topâ€‘k vector search\nâ€¢ retrieve_event_info(text)    â€“ alias of query(text, 5)\nâ€¢ retrieve_domain_info(text)   â€“ alias of query(text, 5)\nâ€¢ retrieve_api_docs(text, pls) â€“ same, but filtered by platform meta\nâ€¢ FunctionRetriever            â€“ exposes .query exactly as dynamic.py expects\n\"\"\"\n \nimport os\nimport logging\nfrom pathlib import Path\nfrom typing import Sequence, List, Dict, Any\n\nimport chromadb\nfrom chromadb.config import Settings\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\nfrom retrievers import default_pool_size          # â† safe (defined early)\n\nlog = logging.getLogger(__name__)\n\n\nclass ChromaRetriever:\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    # construction\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def __init__(\n        self,\n        *,\n        layer: str = \"FASTAPI\",\n        collection_name: str | None = None,\n    ) -> None:\n        self.layer = layer.upper()\n        base_path  = os.getenv(f\"{self.layer}_CHROMA_DB_PATH\", \"./chroma_dbs/fastapi\")\n        coll_name  = (\n            collection_name\n            or os.getenv(f\"{self.layer}_CHROMA_COLLECTION_PLATFORM\", \"platform-summaries-index\")\n        )\n\n        self.path = Path(base_path).expanduser().resolve() / coll_name\n        if not self.path.exists():\n            raise FileNotFoundError(\n                f\"Chroma collection directory '{self.path}' not found.\"\n            )\n\n        client = chromadb.PersistentClient(\n            path=str(self.path),\n            settings=Settings(anonymized_telemetry=False),\n        )\n        self.col = client.get_or_create_collection(coll_name)\n\n        # â”€â”€ concurrency knobs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n        self.pool_size = default_pool_size(self.layer, \"chroma\", fallback=4)\n        print(\n            f\"[{self.layer}/ChromaRetriever]  âš™  workers = {self.pool_size}\",\n            flush=True,\n        )\n\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    # core query helpers\n    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    def _query_one(\n        self,\n        text: str,\n        *,\n        k: int,\n        where_clause: Dict[str, Any] | None,\n    ) -> List[dict]:\n        res = self.col.query(\n            query_texts=[text],\n            n_results=k,\n            include=[\"documents\", \"distances\", \"metadatas\"],\n            where=where_clause,\n        )\n        docs  = res.get(\"documents\", [[]])[0]\n        metas = res.get(\"metadatas\", [[]])[0]\n        dists = (res.get(\"distances\") or [[None]])[0]\n\n        return [\n            {\"content\": doc, **(meta or {}), \"distance\": dist}\n            for doc, meta, dist in zip(docs, metas, dists)\n        ]\n\n    # public â€“ single text ------------------------------------------------\n    def query(\n        self,\n        text: str,\n        *,\n        k: int = 5,\n        filter: Dict[str, Any] | None = None,\n    ) -> List[dict]:\n        return self._query_one(text, k=k, where_clause=filter)\n\n    # public â€“ many texts (parallel) -------------------------------------\n    def query_many(\n        self,\n        texts: Sequence[str],\n        *,\n        k: int = 5,\n        filter: Dict[str, Any] | None = None,\n    ) -> List[List[dict]]:\n        if not texts:\n            return []\n\n        with ThreadPoolExecutor(max_workers=self.pool_size) as pool:\n            futs = {\n                pool.submit(self._query_one, t, k=k, where_clause=filter): idx\n                for idx, t in enumerate(texts)\n            }\n            results: List[List[dict]] = [None] * len(texts)  # type: ignore\n            for fut in as_completed(futs):\n                results[futs[fut]] = fut.result()\n        return results\n\n    # convenience aliases -------------------------------------------------\n    def retrieve_domain_info(self, text: str) -> List[dict]:\n        return self.query(text, k=5)\n\n    def retrieve_api_docs(\n        self,\n        text: str,\n        platforms: Sequence[str],\n    ) -> List[dict]:\n        if not platforms:\n            return []\n        return self.query(text, k=8, filter={\"platform\": {\"$in\": list(platforms)}})\n\n\n# ------------------------------------------------------------------------------\n# adapter that dynamic.py expects ----------------------------------------------\nclass FunctionRetriever:\n    def __init__(self, collection_name: str) -> None:\n        self._inner = ChromaRetriever(collection_name=collection_name)\n\n    def query(self, *args, **kwargs):\n        return self._inner.query(*args, **kwargs)\n"
  },
  {
    "path": "retrievers/elastic_retriever.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/retrievers/elastic_retriever.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n \n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n\nimport os\nfrom typing import List\nfrom elasticsearch import Elasticsearch\n#from app.llm.llm_factory import AzureOpenAIClient\n\nclass ElasticRetriever:\n    \"\"\"\n    A retriever that uses Elasticsearch for vector-based (and/or hybrid) retrieval.\n    \"\"\"\n\n    def __init__(self):\n        self.elastic_host = os.getenv(\"ELASTIC_HOST\", \"http://localhost:9200\")\n        self.elastic_user = os.getenv(\"ELASTIC_USERNAME\", \"elastic\")\n        self.elastic_pass = os.getenv(\"ELASTIC_PASSWORD\", \"changeme\")\n        self.elastic_index = os.getenv(\"ELASTIC_INDEX\", \"cisco_docs\")\n        self.elastic_vector_field = os.getenv(\"ELASTIC_VECTOR_FIELD\", \"embedding\")\n        # For hybrid, you might store the text in a field named \"content\" and the vector in \"embedding\".\n        self.es = Elasticsearch(\n            self.elastic_host,\n            basic_auth=(self.elastic_user, self.elastic_pass),\n            verify_certs=False\n        )\n\n        # For embeddings\n        #self.llm_client = AzureOpenAIClient()\n\n    def retrieve_documents(self, user_input: str, top_k: int = 5) -> List[str]:\n        \"\"\"\n        1) Get embedding for user_input\n        2) Query Elasticsearch (k-NN or hybrid)\n        3) Return doc chunks\n        \"\"\"\n        embedding = self.llm_client.get_embedding(user_input)\n\n        # EXAMPLE: a simple vector query in ES 8.x\n        # If you want strictly vector search:\n        # (Note: the field \"embedding\" must be mapped as a dense_vector or similar.)\n        query = {\n            \"size\": top_k,\n            \"query\": {\n                \"knn\": {\n                    self.elastic_vector_field: {\n                        \"vector\": embedding,\n                        \"k\": top_k\n                    }\n                }\n            }\n        }\n\n        # If you want a hybrid approach (BM25 + vector), you can do something like:\n        # query = {\n        #   \"size\": top_k,\n        #   \"query\": {\n        #       \"bool\": {\n        #           \"should\": [\n        #               { \"match\": { \"content\": user_input } },\n        #               {\n        #                   \"script_score\": {\n        #                       \"query\": {\"match_all\": {}},\n        #                       \"script\": {\n        #                           \"source\": f\"cosineSimilarity(params.queryVector, '{self.elastic_vector_field}') + 1.0\",\n        #                           \"params\": {\"queryVector\": embedding}\n        #                       }\n        #                   }\n        #               }\n        #           ]\n        #       }\n        #   }\n        # }\n\n        response = self.es.search(index=self.elastic_index, body=query)\n\n        docs = []\n        hits = response[\"hits\"][\"hits\"]\n        for hit in hits:\n            # If your document content is stored in e.g. \"content\" field:\n            doc_text = hit[\"_source\"].get(\"content\", \"\")\n            docs.append(doc_text.strip())\n\n        return docs\n"
  },
  {
    "path": "retrievers/null_retriever.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## ai-building-blocks-agent/retrievers/null_retriever.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n \n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n\nclass NullRetriever:\n    \"\"\"\n    A retriever that always returns an empty list (i.e., no documents).\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def retrieve_documents(self, query: str, top_k: int) -> list:\n        \"\"\"\n        Always returns an empty list.\n        :param query: The search query.\n        :param top_k: The number of documents to 'retrieve'â€”in this case, none.\n        :return: Empty list.\n        \"\"\"\n        return []\n"
  },
  {
    "path": "scripts/__init__.py",
    "content": "#suite-cisco-ai-building-blocks/ai-building-blocks-agent/scripts/__init__.py\nimport sys, types\n "
  },
  {
    "path": "scripts/index_functions.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## AI-Building-Blocks-Agent/scripts/index_functions.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n\n\"\"\"\nIndex every *diet* function schema (or a single platform) into the vector-store\nselected for the FASTAPI layer.  Supports Chroma, Azure AI Search, and\nElasticsearch.\n\nExamples\n--------\n# one platform\npython -m scripts.index_functions --platform meraki\n\n# everything under app/llm/function_definitions\npython -m scripts.index_functions --all\n\"\"\"\n# â”€â”€ stdlib â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport argparse\nimport importlib\nimport json\nimport os\nimport sys\nfrom pathlib import Path\nfrom types import ModuleType\n# â”€â”€ third-party â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfrom dotenv import load_dotenv\n# â”€â”€ internal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfrom scripts.utils.paths import ensure_abs_env   # new helper\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 0.  Environment & basic paths\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nload_dotenv()\n\nREPO_ROOT: Path = Path(__file__).resolve().parents[1]            # ai-building-blocks-agent/\nLLM_DIR     = REPO_ROOT / \"app\" / \"llm\"\nDIET_DIR    = LLM_DIR / \"function_definitions\"\nFULL_DIR    = LLM_DIR / \"openapi_specs\"\n\nBACKEND     = os.getenv(\"FASTAPI_VECTOR_BACKEND\", \"chroma\").lower()\n\n# â”€â”€ guarantee absolute Chroma path (only when using Chroma) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nif BACKEND == \"chroma\":\n    # layer-scoped DB path (repo-relative default)\n    ensure_abs_env(\"FASTAPI_CHROMA_DB_PATH\", \"chroma_dbs/fastapi\")\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 1.  Import the correct indexer implementation\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nINDEXER_MODULES: dict[str, str] = {\n    \"chroma\":  \"db_scripts.indexers.chroma_indexer\",\n    \"azure\":   \"db_scripts.indexers.azure_indexer\",\n    \"elastic\": \"db_scripts.indexers.elastic_indexer\",\n}\n\ntry:\n    Indexer = getattr(\n        importlib.import_module(INDEXER_MODULES[BACKEND]),\n        \"PlatformFunctionIndexer\"\n    )\nexcept KeyError as exc:\n    raise RuntimeError(\n        f\"Unsupported backend '{BACKEND}'. \"\n        f\"Choose from: {', '.join(INDEXER_MODULES)}.\"\n    ) from exc\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 2.  Index a single platform\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\ndef index_one(platform: str) -> None:\n    diet_path = DIET_DIR  / f\"{platform}.json\"\n    full_path = FULL_DIR  / f\"full_{platform}.json\"\n\n    if not diet_path.exists():\n        raise FileNotFoundError(f\"Missing diet schema: {diet_path}\")\n    if not full_path.exists():\n        raise FileNotFoundError(f\"Missing full OpenAPI spec: {full_path}\")\n\n    diet_fns  = json.loads(diet_path.read_text())\n    full_spec = json.loads(full_path.read_text())\n\n    # Azure OpenAI: function names must be â‰¤ 64 characters\n    for fn in diet_fns:\n        if len(fn.get(\"name\", \"\")) > 64:\n            orig = fn[\"name\"]\n            fn[\"name\"] = orig[:64]\n            print(f\"[WARN] Truncated long function name: {orig!r} â†’ {fn['name']!r}\")\n\n    # collection / index name selected from env for the chosen backend\n    if BACKEND == \"chroma\":\n        index_name = os.getenv(\"FASTAPI_CHROMA_COLLECTION_PLATFORM\",\n                               \"platform-summaries-index\")\n    elif BACKEND == \"azure\":\n        index_name = os.getenv(\"FASTAPI_AZURE_PLATFORM_INDEX\",\n                               \"platform-summaries-index\")\n    else:  # elastic\n        index_name = os.getenv(\"FASTAPI_ELASTIC_PLATFORM_INDEX\",\n                               \"platform-summaries-index\")\n\n    indexer = Indexer(index_name=index_name, layer_name=\"FASTAPI\")\n    print(f\"â†’ indexing {platform} â€¦\", flush=True)\n    indexer.index_functions(platform, diet_fns, full_spec)\n    print(f\"âœ“ {platform}: {len(diet_fns)} functions indexed via {BACKEND}\")\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# 3.  CLI entry-point\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\ndef cli() -> None:\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--platform\", help=\"meraki, catalyst, â€¦\")\n    ap.add_argument(\"--all\", action=\"store_true\",\n                    help=\"index every diet_*.json found\")\n    args = ap.parse_args()\n\n    if args.platform and args.all:\n        raise SystemExit(\"--platform and --all are mutually exclusive\")\n\n    if args.all:\n        platforms = [p.stem for p in DIET_DIR.glob(\"*.json\")]\n    elif args.platform:\n        platforms = [args.platform]\n    else:\n        raise SystemExit(\"Specify --platform <name> or --all\")\n\n    for plat in platforms:\n        index_one(plat)\n\nif __name__ == \"__main__\":\n    cli()\n"
  },
  {
    "path": "scripts/platform_scaffolder.py",
    "content": "#!/usr/bin/env python3\n\"\"\"\nUnified Platform Scaffolder â€“ phase-1\nAUTO-GENERATES:\n\n* app/llm/function_definitions/<platform>.json\n* app/llm/openapi_specs/full_<platform>.json\n* app/llm/platform_clients/<platform>_client.py\n* app/llm/function_dispatcher/<platform>_dispatcher.py\n* app/llm/unified_service/<platform>_service.py\n\"\"\"\nfrom __future__ import annotations\nimport sys\nfrom pathlib import Path\n\nREPO_ROOT = Path(__file__).resolve().parents[1]\nif str(REPO_ROOT) not in sys.path:\n    sys.path.insert(0, str(REPO_ROOT))\n\nimport argparse\nimport json\nimport logging\nimport re\nimport textwrap\nfrom typing import Dict, List\n\nfrom dotenv import load_dotenv\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfrom scripts.utils.openapi_loader import load_spec\nfrom scripts.utils.sdk_loader      import load_client\nfrom scripts.utils.dietify         import dietify_schema\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€ constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nload_dotenv()\n\nROOT = REPO_ROOT\nLLM_DIR = ROOT / \"app\" / \"llm\"\n\nOUT_DIRS = {\n    \"diet\":    LLM_DIR / \"function_definitions\",\n    \"full\":    LLM_DIR / \"openapi_specs\",\n    \"client\":  LLM_DIR / \"platform_clients\",\n    \"disp\":    LLM_DIR / \"function_dispatcher\",\n    \"service\": LLM_DIR / \"unified_service\",\n}\n\nfor p in OUT_DIRS.values():\n    p.mkdir(parents=True, exist_ok=True)\n\nlogging.basicConfig(level=logging.INFO, format=\"%(levelname)s | %(message)s\")\nlog = logging.getLogger(\"scaffolder\")\n\n# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n# â”‚ 1 â”€ package initialisation helpers                                 â”‚\n# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\nDISPATCHER_INIT = OUT_DIRS[\"disp\"] / \"__init__.py\"\nFUNCS_INIT = OUT_DIRS[\"diet\"] / \"__init__.py\"\n\n# 1-a  dispatcher registry (smart Meraki fallback)\nif not DISPATCHER_INIT.exists():\n    DISPATCHER_INIT.write_text(textwrap.dedent(\"\"\"\\\n        \\\"\\\"\\\"\n        Decorator-based dispatcher registry **plus** smart Meraki fallback.\n        AUTO-GENERATED â€“ DO NOT EDIT MANUALLY.\n        \\\"\\\"\\\"\n        from __future__ import annotations\n        import importlib\n        import os\n        from pathlib import Path\n        from typing import Any, Callable, Dict\n        from meraki import DashboardAPI\n\n        _registry: Dict[str, Callable[..., Any]] = {}\n\n        def register(name: str):\n            def _decorator(fn: Callable[..., Any]):\n                _registry[name] = fn\n                return fn\n            return _decorator\n\n        # auto-import sub-dispatchers so their @register executes\n        _pkg_path = Path(__file__).parent\n        for _p in _pkg_path.glob('*_dispatcher.py'):\n            if _p.name != '__init__.py':\n                importlib.import_module(f'{__name__}.{_p.stem}')\n\n        # Meraki SDK fallback\n        def _call_meraki(fname: str, kwargs: Dict[str, Any]):\n            api_key = os.getenv('MERAKI_DASHBOARD_API_KEY')\n            if not api_key:\n                raise ValueError('Meraki dispatch failed: missing MERAKI_DASHBOARD_API_KEY')\n\n            dash = DashboardAPI(api_key=api_key,\n                                suppress_logging=True,\n                                print_console=True)\n\n            if hasattr(dash, fname):\n                return getattr(dash, fname)(**kwargs)\n\n            for attr in dir(dash):\n                if attr.startswith('_'):\n                    continue\n                sub = getattr(dash, attr)\n                if hasattr(sub, fname):\n                    return getattr(sub, fname)(**kwargs)\n\n            raise AttributeError(f'No Meraki SDK method {fname!r} found')\n\n        def dispatch_function_call(name: str, arguments: Dict[str, Any]):\n            if name in _registry:\n                return _registry[name](**arguments)\n            return _call_meraki(name, arguments)\n\n        __all__ = ['dispatch_function_call', 'register']\n    \"\"\"), encoding=\"utf-8\")\n    log.info(\"âœ“ %s\", DISPATCHER_INIT.relative_to(ROOT))\n\n# 1-b  function-definitions loader\nif not FUNCS_INIT.exists():\n    FUNCS_INIT.write_text(textwrap.dedent(f\"\"\"\\\n        # Auto-generated â€“ DO NOT EDIT\n        # {FUNCS_INIT.relative_to(ROOT)}\n        \\\"\\\"\\\"\n        Loads every *.json in this folder into FUNCTION_DEFINITIONS\n            {{ '<platform>': [{{â€¦}}, â€¦ ] , â€¦ }}\n        \\\"\\\"\\\"\n        from __future__ import annotations\n        import json\n        from pathlib import Path\n        from typing import Dict, List, Any\n\n        _DIR = Path(__file__).parent\n        FUNCTION_DEFINITIONS: Dict[str, List[Dict[str, Any]]] = {{}}\n\n        for _fp in _DIR.glob('*.json'):\n            try:\n                FUNCTION_DEFINITIONS[_fp.stem] = json.loads(_fp.read_text(encoding='utf-8'))\n            except Exception as exc:\n                print(f'[function_definitions] âš ï¸  skipped {{_fp.name}}: {{exc}}')\n\n        __all__ = ['FUNCTION_DEFINITIONS']\n    \"\"\"), encoding=\"utf-8\")\n    log.info(\"âœ“ %s\", FUNCS_INIT.relative_to(ROOT))\n\n# 1-c  empty __init__.py for every other folder\nfor folder in OUT_DIRS.values():\n    init_py = folder / \"__init__.py\"\n    if not init_py.exists():\n        init_py.write_text(\n            f\"# Auto-generated â€“ DO NOT EDIT\\n# {init_py.relative_to(ROOT)}\\n\",\n            encoding=\"utf-8\",\n        )\n        log.info(\"âœ“ %s\", init_py.relative_to(ROOT))\n\n# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n# â”‚ 2 â”€ utility functions                                              â”‚\n# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\ndef _write_json(p: Path, obj, *, pretty: bool = False):\n    p.write_text(\n        json.dumps(obj, indent=2 if pretty else None, separators=(\",\", \":\")),\n        encoding=\"utf-8\",\n    )\n    log.info(\"âœ“ %s\", p.relative_to(ROOT))\n\n_identifier_rx = re.compile(r\"[^0-9A-Za-z_]\")\ndef _py_identifier(raw: str, seen: Dict[str, int]) -> str:\n    \"\"\"\n    Convert *raw* into a valid Python identifier and guarantee uniqueness\n    within a dispatcher file using the *seen* registry.\n    \"\"\"\n    ident = _identifier_rx.sub(\"_\", raw)\n    if ident[0].isdigit():\n        ident = f\"op_{ident}\"\n    # prevent collisions if two different raw names normalise identically\n    if ident in seen:\n        seen[ident] += 1\n        ident = f\"{ident}_{seen[ident]}\"\n    else:\n        seen[ident] = 0\n    return ident\n\n\n# â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef _emit_client_stub(platform: str, sdk_module: str) -> None:\n    \"\"\"\n    Write app/llm/platform_clients/<platform>_client.py\n    â€“ searches both root *and* first-level sub-clients for attributes.\n    \"\"\"\n    sdk_cls = load_client(sdk_module)                # e.g. meraki.DashboardAPI\n\n    # â”€â”€ Meraki-specific env guard\n    extra_imports, extra_init = [], []\n    if platform.lower() == \"meraki\":\n        extra_imports.append(\"import os\")\n        extra_init.extend([\n            \"api_key = os.getenv('CISCO_MERAKI_API_KEY')\",\n            \"if not api_key:\",\n            \"    raise ValueError('Missing CISCO_MERAKI_API_KEY environment variable')\",\n            \"kwargs['api_key'] = api_key\",\n            \"\",\n        ])\n\n    lines: list[str] = [\n        f\"# {(OUT_DIRS['client'] / f'{platform}_client.py').relative_to(ROOT)}\",\n        \"# Auto-generated â€“ DO NOT EDIT\",\n        f\"import {sdk_module} as _sdk\",\n        *extra_imports,\n        \"\",\n        f\"class {platform.capitalize()}Client:\",\n        f\"    \\\"\\\"\\\"Thin wrapper around `{sdk_cls.__name__}` with fuzzy attribute lookup.\\\"\\\"\\\"\",\n        \"\",\n        \"    def __init__(self, **kwargs):\",\n        *[f\"        {l}\" for l in extra_init],\n        f\"        self._sdk = _sdk.{sdk_cls.__name__}(**kwargs)\",\n\n        \"\",\n        \"    def __getattr__(self, item):\",\n        \"        # â‘  direct attribute on DashboardAPI\",\n        \"        if hasattr(self._sdk, item):\",\n        \"            return getattr(self._sdk, item)\",\n        \"\",\n        \"        # â‘¡ first-level sub-clients (organizations, networks, â€¦)\",\n        \"        for name in dir(self._sdk):\",\n        \"            if name.startswith('_'):\",\n        \"                continue\",\n        \"            sub = getattr(self._sdk, name)\",\n        \"            if hasattr(sub, item):\",\n        \"                return getattr(sub, item)\",\n        \"\",\n        \"        raise AttributeError(f\\\"{self.__class__.__name__} has no attribute {item!r}\\\")\",\n        \"\",\n    ]\n\n    fp = OUT_DIRS['client'] / f'{platform}_client.py'\n    fp.write_text('\\n'.join(lines), encoding='utf-8')\n    log.info('âœ“ %s', fp.relative_to(ROOT))\n\n\n\n\n\ndef _emit_unified_service(platform: str):\n    code = textwrap.dedent(f\"\"\"\n        # Auto-generated â€“ DO NOT EDIT\n        from app.llm.platform_clients.{platform}_client import {platform.capitalize()}Client\n\n        class {platform.capitalize()}ServiceClient:\n            \\\"\\\"\\\"Generic call-through service used by FastAPI.\\\"\\\"\\\"\n\n            def __init__(self, **sdk_kwargs):\n                self.client = {platform.capitalize()}Client(**sdk_kwargs)\n\n            def call(self, function_name: str, **kwargs):\n                try:\n                    method = getattr(self.client, function_name)\n                except AttributeError:\n                    raise ValueError(\n                        f\"No such method '{{function_name}}' on {platform.capitalize()}Client\"\n                    )\n                return method(**kwargs)\n    \"\"\").strip()\n\n    fp = OUT_DIRS[\"service\"] / f\"{platform}_service.py\"\n    fp.write_text(f\"# {fp.relative_to(ROOT)}\\n\\n{code}\", encoding=\"utf-8\")\n    log.info(\"âœ“ %s\", fp.relative_to(ROOT))\n\n\n \n\n# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n# â”‚ 3 â”€ per-platform scaffolding                                       â”‚\n# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\ndef scaffold_one(\n    platform: str,\n    sdk_module: str,\n    spec_path: Path,\n    include_http: set[str] | None,\n    name_re: re.Pattern | None,\n) -> None:\n\n    full_spec = load_spec(spec_path)\n\n    _write_json(OUT_DIRS[\"full\"] / f\"{platform}.json\", full_spec, pretty=True)\n    _write_json(OUT_DIRS[\"full\"] / f\"full_{platform}.json\", full_spec, pretty=True)\n\n    diet_fns: List[dict] = []\n    safe_name_seen: Dict[str, int] = {}\n\n    for path, path_item in full_spec.get(\"paths\", {}).items():\n        for verb, op in path_item.items():\n            if include_http and verb.upper() not in include_http:\n                continue\n\n            op_id = op.get(\"operationId\") or f\"{verb}_{path}\"\n            if name_re and not name_re.search(op_id):\n                continue\n\n            schema = {\n                \"name\": op_id,\n                \"description\": op.get(\"summary\") or op.get(\"description\", \"\"),\n                \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []},\n            }\n            for p in op.get(\"parameters\", []):\n                # skip any unresolved $ref or otherwise anonymous parameter\n                if \"name\" not in p:\n                    log.warning(\"Skipping parameter without name: %r\", p)\n                    continue\n\n                name = p[\"name\"]\n                schema[\"parameters\"][\"properties\"][name] = {\n                    \"type\": p.get(\"schema\", {}).get(\"type\", \"string\"),\n                    \"description\": p.get(\"description\", \"\"),\n                }\n                if p.get(\"required\"):\n                    schema[\"parameters\"][\"required\"].append(name)\n\n\n            diet_fns.append(dietify_schema(schema))\n\n    _write_json(OUT_DIRS[\"diet\"] / f\"{platform}.json\", diet_fns)\n\n    _emit_client_stub(platform, sdk_module)\n    _emit_unified_service(platform)\n\n    disp_fp = OUT_DIRS[\"disp\"] / f\"{platform}_dispatcher.py\"\n    lines: List[str] = [\n        f\"# {disp_fp.relative_to(ROOT)}\",\n        \"from app.llm.function_dispatcher import register\",\n        f\"from app.llm.platform_clients.{platform}_client import {platform.capitalize()}Client\",\n        \"\",\n    ]\n    for fn in diet_fns:\n        safe_name = _py_identifier(fn[\"name\"], safe_name_seen)\n        lines.append(\n            f\"@register('{fn['name']}')\\n\"\n            f\"def {safe_name}(**kwargs):\\n\"\n            f\"    return {platform.capitalize()}Client().{safe_name}(**kwargs)\\n\"\n        )\n\n    disp_fp.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n    log.info(\"âœ“ %s\", disp_fp.relative_to(ROOT))\n\n# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\n# â”‚ 4 â”€ CLI                                                            â”‚\n# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\ndef _parse_cli():\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--platform\")\n    ap.add_argument(\"--sdk-module\")\n    ap.add_argument(\"--openapi-spec\")\n    ap.add_argument(\"--include-http-methods\")\n    ap.add_argument(\"--name-pattern\")\n    ap.add_argument(\"--all\", action=\"store_true\",\n                    help=\"Scaffold for every full_*.json already present\")\n    return ap.parse_args()\n\ndef main():\n    args = _parse_cli()\n\n    if args.all and (args.platform or args.sdk_module or args.openapi_spec):\n        raise SystemExit(\"--all cannot be used with other flags\")\n\n    if args.all:\n        platforms = [\n            p.stem.replace(\"full_\", \"\") for p in OUT_DIRS[\"full\"].glob(\"full_*.json\")\n        ]\n    else:\n        if not (args.platform and args.sdk_module and args.openapi_spec):\n            raise SystemExit(\"Need --platform, --sdk-module, and --openapi-spec\")\n        platforms = [args.platform]\n\n    include_http = (\n        {m.upper() for m in args.include_http_methods.split(\",\")}\n        if args.include_http_methods\n        else None\n    )\n    name_re = re.compile(args.name_pattern) if args.name_pattern else None\n\n    for plat in platforms:\n        spec = (\n            Path(args.openapi_spec)\n            if args.openapi_spec\n            else OUT_DIRS[\"full\"] / f\"{plat}.json\"\n        )\n        log.info(\"â³ Scaffolding %s â€¦\", plat)\n        scaffold_one(plat, args.sdk_module, spec, include_http, name_re)\n\n    log.info(\"âœ… DONE â€“ all artefacts generated\")\n\nif __name__ == \"__main__\":\n    main()\n"
  },
  {
    "path": "scripts/utils/__init__.py",
    "content": "#suite-cisco-ai-building-blocks/ai-building-blocks-agent/scripts/utils/__init__.py\n"
  },
  {
    "path": "scripts/utils/dietify.py",
    "content": "def dietify_schema(full_schema: dict) -> dict:\n    \"\"\"\n    Return a *diet* version of an OpenAPI function schema:\n    â€“ keep only primitive params (string / integer / number / boolean / array)\n    â€“ drop examples, defaults, complex objects to save tokens\n    \"\"\"\n    keep = {\"string\", \"integer\", \"number\", \"boolean\", \"array\"}\n\n    full_parameters = full_schema.get(\"parameters\", {}).get(\"properties\", {})\n    slimmed = {\n        k: v\n        for k, v in full_parameters.items()\n        if v.get(\"type\") in keep\n    }\n\n    diet = full_schema.copy()\n    diet[\"parameters\"][\"properties\"] = slimmed\n    return diet\n"
  },
  {
    "path": "scripts/utils/openapi_loader.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## AI-Building-Blocks-Agent/scripts/utils/openapi_loader.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\"\"\"\nopenapi_loader.py\n\nTiny helper that loads an OpenAPI document into a Python ``dict``.\n\nâ€¢ Accepts **JSON** (``*.json``) **and YAML** (``*.yml`` / ``*.yaml``).  \nâ€¢ Requires ``PyYAML`` for YAML files â€“ install once with ``pip install pyyaml``.\n\"\"\"\n\nfrom pathlib import Path\nimport json\nfrom typing import Any, Dict\n\n\ndef _load_yaml(text: str) -> Dict[str, Any]:\n    try:\n        import yaml  # type: ignore\n    except ModuleNotFoundError as exc:\n        raise RuntimeError(\n            \"YAML spec detected but PyYAML is not installed.\\n\"\n            \"Fix:  pip install pyyaml\"\n        ) from exc\n    return yaml.safe_load(text)\n\n\ndef load_spec(path: Path) -> dict:\n    \"\"\"\n    Read *path* and return the parsed OpenAPI spec as a dictionary.\n\n    Parameters\n    ----------\n    path : pathlib.Path\n        File ending in .json, .yaml or .yml.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the path doesnâ€™t exist.\n    ValueError\n        If the file extension is unrecognised.\n    RuntimeError\n        If a YAML file is supplied but PyYAML is missing.\n    \"\"\"\n    if not path.exists():\n        raise FileNotFoundError(path)\n\n    ext = path.suffix.lower()\n    text = path.read_text(encoding=\"utf-8\")\n\n    if ext == \".json\":\n        return json.loads(text)\n    if ext in {\".yaml\", \".yml\"}:\n        return _load_yaml(text)\n\n    raise ValueError(f\"Unsupported file extension {ext!r} for {path}\")\n"
  },
  {
    "path": "scripts/utils/paths.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## AI-Building-Blocks-Agent/scripts/utils/paths.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\"\"\"\nPath-handling helpers shared across layers.\n\n* ``ensure_abs_env(var, default_rel)``  \n  Makes sure *var* exists and is an **absolute** path, resolving any relative\n  value against the repo root (parent of ``ai-building-blocks-agent``).\n\n* ``get_chroma_root(layer_env: str, default_rel: str = \"chroma_dbs\")``  \n  Returns the absolute path for *this layerâ€™s* Chroma collections, based solely\n  on the per-layer env-var (no more legacy ``CHROMA_DB_ROOT``).\n\n* ``get_dynamic_cache_dir()``  \n  Ensures and returns the directory pointed to by\n  ``PLATFORM_DYNAMIC_CACHE_PATH`` (or its default).\n\"\"\"\n\nfrom pathlib import Path\nimport os\nfrom typing import Final\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nREPO_ROOT: Final[Path] = Path(__file__).resolve().parents[2]  # ../../\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 1.  Generic helper\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\ndef ensure_abs_env(var: str, default_rel: str) -> Path:\n    raw = os.getenv(var, default_rel)\n    p   = Path(raw).expanduser()\n    if not p.is_absolute():\n        p = (REPO_ROOT / p).resolve()\n    os.environ[var] = str(p)\n    return p\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 2.  Chroma collections (per layer)\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\ndef get_chroma_root(layer_env: str, default_rel: str = \"chroma_dbs\") -> Path:\n    \"\"\"\n    Resolve the folder that stores *layer-specific* Chroma collections.\n\n    Parameters\n    ----------\n    layer_env:\n        The env-var name, e.g. ``FASTAPI_CHROMA_DB_PATH``.\n    default_rel:\n        Fallback relative path (resolved under the repo root).\n\n    Returns\n    -------\n    pathlib.Path\n        Absolute path to the collection directory.\n    \"\"\"\n    return ensure_abs_env(layer_env, default_rel)\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 3.  Platform-function dynamic cache\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\ndef get_dynamic_cache_dir() -> Path:\n    cache = ensure_abs_env(\n        \"PLATFORM_DYNAMIC_CACHE_PATH\",\n        \"ai-building-blocks-agent/app/platform_dynamic_cache\",\n    )\n    Path(cache).mkdir(parents=True, exist_ok=True)\n    return Path(cache)\n"
  },
  {
    "path": "scripts/utils/sdk_loader.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## AI-Building-Blocks-Agent/scripts/utils/sdk_loader.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\n\"\"\"\nUtility to locate the main *client* class in a vendor SDK so that the scaffolder\ncan wrap it automatically.\n\nMatching rules â€” in order of preference â€” are:\n\n1.  Class name ends with **DashboardAPI**        (e.g. ``DashboardAPI``)\n2.  Class name ends with **Client**              (e.g. ``MerakiClient``)\n3.  Class name ends with **API**                 (e.g. ``DNACenterAPI``)\n4.  Class name ends with **Session**             (e.g. ``ManagerSession``)\n\nThe comparison is case-insensitive.  The first match encountered is returned.\n\"\"\"\n\nimport importlib\nimport inspect\nfrom types import ModuleType\nfrom typing import Type, Any\n\n\ndef load_client(module_name: str) -> Type[Any]:\n    \"\"\"\n    Dynamically import *module_name* and return the first class that looks like\n    an SDK entry-point according to the rules above.\n\n    Parameters\n    ----------\n    module_name : str\n        The fully-qualified name of the SDK module, e.g. ``\"meraki\"``,\n        ``\"dnacentersdk\"``.\n\n    Raises\n    ------\n    RuntimeError\n        If no suitable client class is found.\n\n    Examples\n    --------\n    >>> load_client(\"meraki\").__name__\n    'DashboardAPI'\n    >>> load_client(\"dnacentersdk\").__name__\n    'DNACenterAPI'\n    \"\"\"\n    mod: ModuleType = importlib.import_module(module_name)\n\n    for attr in dir(mod):\n        obj = getattr(mod, attr)\n        if not inspect.isclass(obj):\n            continue\n\n        lower_name = attr.lower()\n        if lower_name.endswith(\"dashboardapi\") or lower_name.endswith(\"client\") or lower_name.endswith(\"api\") or lower_name.endswith(\"session\"):\n            return obj\n\n    raise RuntimeError(f\"No SDK client found in {module_name!r}\")\n"
  },
  {
    "path": "static/index.html",
    "content": "\n<!--\n################################################################################\n## ai-building-blocks-agent/static/index.html\n## Copyright (c) 2025 Cisco Systems\n## Licensed under the Apache License, Version 2.0  (see LICENSE)\n################################################################################\nDISCLAIMER: USE AT YOUR OWN RISK â€“ see repository README for details.\n-->\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\" />\n  <title>Cisco AI Building Blocks AI Agent</title>\n  <link rel=\"icon\" type=\"image/x-icon\" href=\"/assets/favicon.ico\" />\n  <style>\n    body{font-family:Arial,Helvetica,sans-serif;margin:0;background:#f6f6f6;color:#333}\n    header{display:flex;align-items:center;padding:10px 20px;background:#005073;color:#fff}\n    header img{height:40px;margin-right:15px}\n    header h1{font-size:1.5rem;margin:0}\n    .container{width:90%;margin:40px auto;background:#fff;border-radius:8px;box-shadow:0 0 10px rgba(0,0,0,.1)}\n    #messages{padding:20px;height:65vh;overflow-y:auto;line-height:1.4;border-bottom:1px solid #ccc}\n    #messages div{margin-bottom:10px}\n    #messages .user{color:#007DAA;font-weight:bold}\n    #messages .assistant{color:#333}\n    .assistant-label{font-weight:bold;color:#007DAA;margin-bottom:5px}\n    table{width:100%;border-collapse:collapse}\n    th,td{border:1px solid #ccc;padding:8px;text-align:left}\n    th{background:#005073!important;color:#fff!important}\n    .collapsible{background:#f9f9f9;color:#333;cursor:pointer;padding:10px;border:1px solid #ccc;text-align:left;font-size:16px;margin-bottom:5px}\n    .collapsible.active{background:#e9e9e9}\n    .content{display:none;background:#f1f1f1;border:1px solid #ccc;margin-bottom:10px;padding:0 15px}\n    #input-area{display:flex;padding:10px 20px;align-items:center;gap:10px;background:#f1f1f1}\n    #user-input{flex:1;padding:8px;font-size:1rem}\n    button{background:#005073;color:#fff;border:none;padding:8px 16px;font-size:1rem;border-radius:4px;cursor:pointer}\n    button:hover{background:#007DAA}\n    pre{white-space:pre-wrap;margin:10px 0;padding:10px;background:#f6f6f6;border:1px solid #ccc}\n  </style>\n</head>\n<body>\n<header>\n  <img src=\"/assets/Cisco_Logo_White.png\" alt=\"Cisco Logo\" />\n  <h1>Cisco AI Building Blocks AI Agent<h1>\n</header>\n\n<div class=\"container\">\n  <div id=\"messages\"></div>\n  <div id=\"input-area\">\n    <input type=\"text\" id=\"user-input\" placeholder=\"Type a message...\" autocomplete=\"off\" />\n    <button id=\"send-btn\">Send</button>\n    <button id=\"clear-btn\">ğŸ§¹</button>\n    <button id=\"toggle-btn\">Toggle View</button>\n    <button id=\"download-btn\">Download JSON</button>\n  </div>\n</div>\n\n<script>\n/* ---------- DOM refs --------------------------------------------------- */\nconst messagesDiv = document.getElementById('messages');\nconst userInput    = document.getElementById('user-input');\nconst sendBtn      = document.getElementById('send-btn');\nconst clearBtn     = document.getElementById('clear-btn');\nconst toggleBtn    = document.getElementById('toggle-btn');\nconst downloadBtn  = document.getElementById('download-btn');\n\n/* ---------- Helpers ---------------------------------------------------- */\nconst API_ROOT = window.location.pathname.replace(/\\/$/, ''); // \"\" or \"/some/prefix\"\n\nfunction removeTripleBackticks(str){return String(str).replaceAll(\"```\",\"\");}\n\n/** Convert raw text|json|markdown to nice HTML (collapsibles, tables, etc.). */\nfunction parseResponseToHtml(responseText){\n  responseText = removeTripleBackticks(responseText);\n  const trimmed = String(responseText).trim();\n\n  /* A. Raw HTML â€“ show as-is */\n  if(trimmed.startsWith(\"<\") || /<(strong|p|h[1-6]|table|div|ul|li)\\b/i.test(trimmed)){\n    return trimmed;\n  }\n\n  /* B. JSON (object or array) */\n  if(/^[\\[{]/.test(trimmed)){\n    try{\n      const json = JSON.parse(trimmed);\n      return Array.isArray(json) ? createHtmlTable(json) : createCollapsibleHtml(json);\n    }catch{ /* fallthrough */ }\n  }\n\n  /* C. Markdown lite */\n  if(trimmed.includes(\"**\") || trimmed.includes(\"- \")){ return formatMarkdownAsHtml(trimmed); }\n\n  /* D. Plain text fallback */\n  return `<p>${trimmed}</p>`;\n}\n\nfunction createCollapsibleHtml(obj, lvl=0){\n  let html=\"\";\n  for(const [k,v] of Object.entries(obj)){\n    if(typeof v===\"object\" && v!==null){\n      html += `<button class=\"collapsible\">${'&nbsp;'.repeat(lvl*2)}${k}</button>`;\n      html += `<div class=\"content\">${createCollapsibleHtml(v, lvl+1)}</div>`;\n    }else{\n      html += `<p>${'&nbsp;'.repeat(lvl*2)}<strong>${k}:</strong> ${v}</p>`;\n    }\n  }\n  return html;\n}\n\nfunction createHtmlTable(arr){\n  if(!Array.isArray(arr)||!arr.length){return \"<p>No data.</p>\";}\n  const heads = Object.keys(arr[0]);\n  let h=`<table><thead><tr>${heads.map(h=>`<th>${h}</th>`).join(\"\")}</tr></thead><tbody>`;\n  arr.forEach(r=>{\n    h+=\"<tr>\"+heads.map(c=>`<td>${r[c]??\"\"}</td>`).join(\"\")+\"</tr>\";\n  });\n  return h+\"</tbody></table>\";\n}\n\nfunction formatMarkdownAsHtml(md){\n  return md.split(\"\\n\").map(line=>{\n    if(line.startsWith(\"**\"))          return `<p><strong>${line.replace(/\\*\\*/g,\"\")}</strong></p>`;\n    else if(line.startsWith(\"-\"))      return `<li>${line.slice(1).trim()}</li>`;\n    else                               return `<p>${line}</p>`;\n  }).join(\"\");\n}\n\n/* ---------- Chat logic -------------------------------------------------- */\nlet isHtmlView = true;\nconst chatHistory = [];\n\nasync function sendMessage(){\n  const query = userInput.value.trim();\n  if(!query) return;\n\n  /* user bubble */\n  messagesDiv.insertAdjacentHTML(\"beforeend\", `<div class=\"user\">User: ${query}</div>`);\n  userInput.value = \"\";\n\n  try{\n    const res = await fetch(`${API_ROOT}/chat`, {\n      method:\"POST\",\n      headers:{'Content-Type':'application/json'},\n      body:JSON.stringify({message:query})\n    });\n    const data  = await res.json();\n\n    const label = data.label ?? \"Assistant\";\n    const html  = parseResponseToHtml(data.response ?? \"No response.\");\n    const json  = JSON.stringify(data,null,2);\n    chatHistory.push({html,json});\n\n    const msgHtml = `<div class=\"assistant\">\n                       <div class=\"assistant-label\">${label}:</div>\n                       ${isHtmlView ? html : `<pre>${json}</pre>`}\n                     </div>`;\n    messagesDiv.insertAdjacentHTML(\"beforeend\", msgHtml);\n    messagesDiv.scrollTop = messagesDiv.scrollHeight;\n  }catch(err){ console.error(\"Fetch error:\", err); }\n}\n\n/* ---------- UI bindings ------------------------------------------------- */\nsendBtn  .addEventListener(\"click\", sendMessage);\nuserInput.addEventListener(\"keypress\", e=>{if(e.key===\"Enter\") sendMessage();});\n\nclearBtn .addEventListener(\"click\", ()=>{\n  messagesDiv.innerHTML=\"\"; userInput.value=\"\"; chatHistory.length=0;\n});\n\ntoggleBtn.addEventListener(\"click\",()=>{\n  isHtmlView = !isHtmlView;\n  document.querySelectorAll('.assistant').forEach((div,i)=>{\n    const c = chatHistory[i];\n    if(!c) return;\n    div.innerHTML = isHtmlView\n      ? `<div class=\"assistant-label\">${JSON.parse(c.json).label ?? \"Assistant\"}:</div>${c.html}`\n      : `<pre>${c.json}</pre>`;\n  });\n});\n\ndownloadBtn.addEventListener(\"click\",()=>{\n  const blob = new Blob([chatHistory.map(c=>c.json).join(\"\\n\")],{type:\"application/json\"});\n  const url  = URL.createObjectURL(blob);\n  const a    = document.createElement(\"a\");\n  a.href=url; a.download=\"chat_history.json\"; a.click(); URL.revokeObjectURL(url);\n});\n\n/* ---------- collapsible handler ---------------------------------------- */\ndocument.addEventListener(\"click\",e=>{\n  if(e.target.classList.contains(\"collapsible\")){\n    e.target.classList.toggle(\"active\");\n    const c=e.target.nextElementSibling;\n    if(c){c.style.display = c.style.display===\"block\"?\"none\":\"block\";}\n  }\n});\n</script>\n</body>\n</html>\n"
  },
  {
    "path": "tools/__init__.py",
    "content": "#stub"
  },
  {
    "path": "tools/compare_diet_full.py",
    "content": "#!/usr/bin/env python3\n###########################################################################################\n## suite-cisco-ai-building-blocks/ai-building-blocks-agent/tools/compare_diet_full.py\n## Copyright (c) 2025 Jeff Teeter, Ph.D.\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n###########################################################################################\nfrom __future__ import annotations\n\n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n\n\"\"\"\nQuick utility for **spot-querying the FASTAPI layerâ€™s Chroma DB**.\n\nRun it when you want to inspect which diet-function records are stored for a\nparticular pattern (e.g. any function whose name starts with â€œgetOrganizationâ€).\nIt connects to the collection defined by FASTAPI_CHROMA_DB_PATH /\nFASTAPI_CHROMA_COLLECTION_PLATFORM, filters the documents, and dumps the hits\nas JSONL right next to this script in ai-building-blocks-agent/tools/.\n\"\"\"\nimport os\nimport json\nfrom pathlib import Path\n\n# â”€â”€ 1. Locate your diet file and full spec â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nROOT       = Path(__file__).resolve().parents[1]\nDIET_PATH  = ROOT / \"app\" / \"llm\" / \"function_definitions\" / \"meraki.json\"\nFULL_PATH  = ROOT / \"app\" / \"llm\" / \"openapi_specs\" / \"full_meraki.json\"\n\n# â”€â”€ 2. Load them â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndiet      = json.loads(DIET_PATH.read_text(encoding=\"utf-8\"))\nfull_spec = json.loads(FULL_PATH.read_text(encoding=\"utf-8\"))\n\n# â”€â”€ 3. Extract operationIds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndiet_ids = {fn[\"name\"] for fn in diet}\n\nfull_ids = {\n    op[\"operationId\"]\n    for path_item in full_spec.get(\"paths\", {}).values()\n    for op in path_item.values()\n    if \"operationId\" in op\n}\n\n# â”€â”€ 4. Compute differences â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nmissing_in_diet = sorted(full_ids - diet_ids)\nextra_in_diet   = sorted(diet_ids - full_ids)\n\nreport = {\n    \"missing_in_diet\": missing_in_diet,\n    \"extra_in_diet\":   extra_in_diet,\n}\n\n# â”€â”€ 5. Write report to disk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nOUTFILE = \"diet_vs_full_report.json\"\nPath(OUTFILE).write_text(json.dumps(report, indent=2), encoding=\"utf-8\")\n\nprint(f\"âœ… Report written to {OUTFILE}\")\nprint(f\" â€¢ missing_in_diet: {len(missing_in_diet)} items\")\nprint(f\" â€¢ extra_in_diet:   {len(extra_in_diet)} items\")\n"
  },
  {
    "path": "tools/create_index.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## suite-cisco-ai-building-blocks/ai-building-blocks-agent/tools/create_index.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\n\"\"\"\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Platform Indexer Wizard â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘ A polished step-by-step CLI to run the index_functions script without the flags. â•‘\nâ•‘ Hover over links or type '?' at prompts for examples.                            â•‘\nâ•‘                                                                                  â•‘\nâ•‘ FEATURES                                                                          â•‘\nâ•‘   â€¢ Select a single platform or index ALL platforms                                â•‘\nâ•‘   â€¢ Automatically configures PYTHONPATH                                             â•‘\nâ•‘   â€¢ Shows the exact command in a copyable block                                    â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\"\"\"\n\nimport argparse\nimport os\nimport shlex\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\nfrom rich.table import Table\nfrom rich.markdown import Markdown\nfrom rich import box\nfrom rich.traceback import install\n\ninstall()\nconsole = Console()\n\n# Paths and patterns\nAGENT_ROOT = Path(__file__).resolve().parents[1]\nINDEXER_SCRIPT = AGENT_ROOT / \"scripts\" / \"index_functions.py\"\nLLM_DEF_DIR = AGENT_ROOT / \"app\" / \"llm\" / \"function_definitions\"\n\n# Helpers\n\ndef clear_screen() -> None:\n    if sys.stdout.isatty():\n        os.system(\"cls\" if os.name == \"nt\" else \"clear\")\n\n\ndef list_platforms() -> List[Tuple[int, str]]:\n    plats = sorted(fp.stem for fp in LLM_DEF_DIR.glob(\"*.json\"))\n    if not plats:\n        console.print(\"[red]No platform JSON files found.[/red]\")\n        sys.exit(1)\n    table = Table(box=box.SIMPLE_HEAVY)\n    table.add_column(\"#\", style=\"bold cyan\")\n    table.add_column(\"Platform\")\n    for i, name in enumerate(plats, 1):\n        table.add_row(str(i), name)\n    console.print(Panel(table, title=\"Step 1/3: Select Platform (or type 'all')\", border_style=\"cyan\"))\n    return list(enumerate(plats, 1))\n\n\ndef ask_choice(prompt: str, default: Optional[str] = None) -> str:\n    resp = Prompt.ask(f\"[cyan]?[/cyan] [bold]{prompt}[/bold]\", default=default)\n    return resp.strip()\n\n\ndef build_command(platform: Optional[str]) -> List[str]:\n    if platform:\n        return [sys.executable, str(INDEXER_SCRIPT), \"--platform\", platform]\n    return [sys.executable, str(INDEXER_SCRIPT), \"--all\"]\n\n# Main\n\ndef main() -> None:\n    clear_screen()\n    console.print(Panel.fit(\"ğŸ›  Welcome to the Platform Indexer Wizard\", style=\"green\"))\n\n    # Step 1: choose platform\n    listing = list_platforms()\n    choice = ask_choice(\"Enter number or 'all' to index all\", \"all\")\n    if choice.lower() == \"all\":\n        platform = None\n    else:\n        try:\n            idx = int(choice)\n            platform = next(name for n, name in listing if n == idx)\n        except Exception:\n            console.print(\"[red]Invalid selection. Exiting.[/red]\")\n            sys.exit(1)\n    console.print(f\":white_check_mark: Selected [bold]{platform or 'All'}[/bold]\\n\")\n\n    # Step 2: preview command\n    cmd_parts = build_command(platform)\n    cmd_str = \" \".join(shlex.quote(p) for p in cmd_parts)\n    console.print(\n        Panel(\n            Markdown(f\"**Command to run**\\n```bash\\n{cmd_str}\\n```\"),\n            border_style=\"cyan\",\n            title=\"Step 2/3: Preview Command\"\n        )\n    )\n\n    # Step 3: confirmation\n    proceed = ask_choice(\"Proceed with indexing? (Y/n)\", \"Y\")\n    if proceed.lower().startswith(\"n\"):\n        console.print(\"[yellow]Aborted by user.[/yellow]\")\n        return\n\n    # Execute\n    console.print(Panel.fit(\"ğŸš€ Running indexer...\", style=\"cyan\"))\n    env = os.environ.copy()\n    env[\"PYTHONPATH\"] = f\"{AGENT_ROOT}:{env.get('PYTHONPATH','')}\"\n    subprocess.run(cmd_parts, check=True, env=env)\n    console.print(Panel.fit(\":white_check_mark: Indexing complete!\", style=\"green\"))\n\nif __name__ == \"__main__\":\n    try:\n        main()\n    except KeyboardInterrupt:\n        console.print(\"\\n[red]Interrupted by user.[/red]\")\n"
  },
  {
    "path": "tools/create_platform.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## AI-Building-Blocks-Agent/tools/create_platform.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\n\"\"\"\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Unified Platform Scaffolder Wizard â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘ A step-by-step CLI tool to generate AI agent scaffolding with a polished UX.      â•‘\nâ•‘ Hover over links or type '?' at prompts for examples.                             â•‘\nâ•‘                                                                                   â•‘\nâ•‘ OUTPUT                                                                            â•‘\nâ•‘   â€¢ app/llm/function_definitions/<platform>.json                                  â•‘\nâ•‘   â€¢ app/llm/openapi_specs/full_<platform>.json                                    â•‘\nâ•‘   â€¢ app/llm/platform_clients/<platform>_client.py                                 â•‘\nâ•‘   â€¢ app/llm/function_dispatcher/<platform>_dispatcher.py                          â•‘\nâ•‘   â€¢ app/llm/unified_service/<platform>_service.py                                 â•‘\nâ•‘                                                                                   â•‘\nâ•‘ PREREQUISITES                                                                     â•‘\nâ•‘   â€¢ Install SDK (pip) or ensure PYTHONPATH includes your SDK module.               â•‘\nâ•‘   â€¢ Provide a valid JSON/YAML OpenAPI spec.                                       â•‘\nâ•‘   â€¢ If a workflow diagram exists, it will open externally for review.              â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\"\"\"\n\nimport argparse\nimport subprocess\nimport sys\nimport os\nimport re\nimport webbrowser\nimport shlex\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\nfrom itertools import chain\nfrom typing import List, Optional, Tuple\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.table import Table\nfrom rich.prompt import Prompt\nfrom rich.markdown import Markdown\nfrom rich import box\nfrom rich.traceback import install\n\ninstall()\nconsole = Console()\n\n# Paths\nAGENT_ROOT = Path(__file__).resolve().parents[1]\nSPEC_DIR = AGENT_ROOT.parent / \"ai-building-blocks-database\" / \"source_open_api\"\nif str(AGENT_ROOT) not in sys.path:\n    sys.path.insert(0, str(AGENT_ROOT))\n\n# SDK list file for platform choices\nSDK_LIST_FILE = AGENT_ROOT / \"app\" / \"llm\" / \"sdk_list.json\"\ntry:\n    sdk_list = json.loads(SDK_LIST_FILE.read_text(encoding=\"utf-8\"))\nexcept Exception:\n    sdk_list = []\n\n# Validation patterns\nVALID_PLATFORM_RX = re.compile(r\"^[a-z][a-z0-9_]*$\")\nVALID_VERBS = {\"GET\",\"POST\",\"PUT\",\"PATCH\",\"DELETE\",\"HEAD\",\"OPTIONS\"}\n\n# Example links and diagram\nEXAMPLE_LINK = \"https://example.com/create-platform-examples\"\nDIAGRAM_PATH = AGENT_ROOT / \"docs\" / \"create_platform_flow.png\"\n\n# Helpers\n\ndef clear_screen() -> None:\n    if sys.stdout.isatty():\n        os.system(\"cls\" if os.name == \"nt\" else \"clear\")\n\n\ndef ask(prompt: str, default: Optional[str] = None) -> str:\n    \"\"\"Prompt user; '?' shows examples link. Accepts blank if default is provided.\"\"\"\n    while True:\n        resp = Prompt.ask(f\"[cyan]?[/cyan] [bold]{prompt}[/bold]\", default=default)\n        if resp.strip() == \"?\":\n            console.print(Markdown(f\"[See examples here]({EXAMPLE_LINK})\"))\n            try:\n                webbrowser.open(EXAMPLE_LINK)\n            except Exception:\n                pass\n            continue\n        val = resp.strip()\n        if default is not None:\n            return val\n        if val:\n            return val\n        console.print(\"[red]â†’ Please enter a value.[/red]\\n\")\n\n\ndef pick_spec() -> str:\n    console.print(Panel.fit(\"Step 2/4: Choose OpenAPI spec\", style=\"cyan\"))\n    specs = sorted(chain(SPEC_DIR.glob(\"*.json\"), SPEC_DIR.glob(\"*.yaml\"), SPEC_DIR.glob(\"*.yml\")))\n    table = Table(box=box.SIMPLE_HEAVY)\n    table.add_column(\"#\", style=\"bold cyan\")\n    table.add_column(\"File\")\n    table.add_column(\"Size (KB)\", justify=\"right\")\n    table.add_column(\"Modified\")\n    for i, fp in enumerate(specs, 1):\n        table.add_row(\n            str(i), fp.name,\n            str(fp.stat().st_size // 1024),\n            datetime.fromtimestamp(fp.stat().st_mtime).strftime(\"%Y-%m-%d\"),\n        )\n    console.print(table)\n    choice = ask(\"Select spec number\", \"1\")\n    if choice.isdigit() and (idx := int(choice)) > 0 and idx <= len(specs):\n        return str(specs[idx-1])\n    return ask(\"Enter path to OpenAPI spec\", None)\n\n\ndef preview_table(rows: List[Tuple[str, str]]) -> None:\n    \"\"\"Display a preview table with rounded borders.\"\"\"\n    table = Table(box=box.ROUNDED, padding=(0, 1))\n    table.add_column(justify=\"right\", style=\"bold green\", no_wrap=True)\n    table.add_column()\n    for key, value in rows:\n        table.add_row(f\"{key}:\", value)\n    console.print(Panel(table, title=\"Preview Configuration\", border_style=\"cyan\"))\n\n# Main flow\n\ndef main() -> None:\n    clear_screen()\n    parser = argparse.ArgumentParser(add_help=False)\n    parser.add_argument(\"--dry-run\", action=\"store_true\")\n    args, _ = parser.parse_known_args()\n\n    console.print(Panel.fit(\"ğŸ›  Welcome to the Unified Platform Scaffolder Wizard\", style=\"green\"))\n\n    # Step 1/4: Platform identifier\n    console.print(Panel.fit(\"Step 1/4: Platform identifier\", style=\"cyan\"))\n    if sdk_list:\n        table = Table(box=box.SIMPLE)\n        table.add_column(\"#\", style=\"bold cyan\")\n        table.add_column(\"Platform\")\n        for i, name in enumerate(sdk_list, start=1):\n            table.add_row(str(i), name)\n        console.print(table)\n        while True:\n            choice = ask(\"Select platform number or enter custom\", None)\n            if choice.isdigit() and 1 <= (idx := int(choice)) <= len(sdk_list):\n                platform = sdk_list[idx-1]\n                break\n            if not choice.isdigit():\n                platform = choice\n                break\n            console.print(\"[red]â†’ Invalid selection.[/red]\")\n    else:\n        platform = ask(\"Enter platform (e.g., meraki)\", None)\n\n    while not VALID_PLATFORM_RX.match(platform):\n        console.print(\"[red]â†’ Invalid platform. Use lowercase letters, digits, and underscores.[/red]\")\n        platform = ask(\"Enter platform (e.g., meraki)\", None)\n    console.print(f\":white_check_mark: Platform set to [bold]{platform}[/bold]\\n\")\n    is_new = platform not in sdk_list\n\n    # Step 1b/4: SDK module import path with choice\n    console.print(Panel.fit(\"Step 1b/4: SDK module import path\", style=\"cyan\"))\n    options = [platform, f\"{platform}.session\"]\n    table = Table(box=box.SIMPLE)\n    table.add_column(\"#\", style=\"bold cyan\")\n    table.add_column(\"Module\")\n    for i, mod in enumerate(options, start=1):\n        table.add_row(str(i), mod)\n    console.print(table)\n    while True:\n        sel = ask(\"Select module number or enter custom\", None)\n        if sel.isdigit() and 1 <= (idx := int(sel)) <= len(options):\n            sdk_module = options[idx-1]\n            break\n        if not sel.isdigit():\n            sdk_module = sel\n            break\n        console.print(\"[red]â†’ Invalid selection.[/red]\")\n    console.print(f\":white_check_mark: SDK module set to [bold]{sdk_module}[/bold]\\n\")\n\n    # Step 2/4: OpenAPI spec\n    spec_file = pick_spec()\n    console.print(f\":white_check_mark: Using spec [bold]{Path(spec_file).name}[/bold]\\n\")\n\n    # Step 3/4: HTTP verbs\n    console.print(Panel.fit(\"Step 3/4: Configure HTTP verbs\", style=\"cyan\"))\n    verbs = ask(\"HTTP verbs (comma-separated, blank=ALL)\", \"GET\").upper()\n    cleaned = [v.strip() for v in verbs.split(\",\") if v.strip() in VALID_VERBS]\n    console.print(f\":white_check_mark: Verbs = [bold]{', '.join(cleaned) or 'ALL'}[/bold]\\n\")\n\n    # Step 4/4: Regex filter\n    console.print(Panel.fit(\"Step 4/4: Regex filter for operationIds\", style=\"cyan\"))\n    name_re = ask(\"Regex filter (blank=none)\", \"\").strip()\n    console.print(f\":white_check_mark: Regex filter = [bold]{name_re or 'None'}[/bold]\\n\")\n\n    # Preview all choices\n    preview_table([\n        (\"Platform\", platform),\n        (\"SDK module\", sdk_module),\n        (\"Spec file\", Path(spec_file).name),\n        (\"HTTP verbs\", ', '.join(cleaned) or \"ALL\"),\n        (\"Name regex\", name_re or \"None\"),\n    ])\n\n    if DIAGRAM_PATH.exists():\n        console.print(Panel.fit(\"Workflow diagram available at:\", border_style=\"cyan\"))\n        console.print(f\"[cyan]file://{DIAGRAM_PATH}[/cyan]\")\n\n    # Build command to invoke platform_scaffolder\n    cmd = [\n        sys.executable,\n        str(AGENT_ROOT / \"scripts\" / \"platform_scaffolder.py\"),\n        \"--platform\", platform,\n        \"--sdk-module\", sdk_module,\n        \"--openapi-spec\", spec_file,\n    ]\n    if cleaned:\n        cmd += [\"--include-http-methods\", ''.join(cleaned)]\n    if name_re:\n        cmd += [\"--name-pattern\", name_re]\n    cmd_str = ' '.join(shlex.quote(c) for c in cmd)\n    console.print(Panel(Markdown(f\"**Command to run**\\n```bash\\n{cmd_str}\\n```\"), border_style=\"cyan\"))\n\n    # Confirm and execute\n    if args.dry_run or ask(\"Proceed? (Y/n)\", \"Y\").lower().startswith(\"n\"):\n        console.print(\"[yellow]Aborted by user.[/yellow]\")\n        return\n\n    console.print(Panel.fit(\"ğŸš€ Running scaffolder...\", style=\"cyan\"))\n    env = os.environ.copy()\n    env[\"PYTHONPATH\"] = f\"{AGENT_ROOT}:{env.get('PYTHONPATH','')}\"\n    subprocess.run(cmd, check=True, env=env)\n\n    # Append new platform to sdk_list.json\n    if is_new:\n        try:\n            sdk_list.append(platform)\n            SDK_LIST_FILE.parent.mkdir(parents=True, exist_ok=True)\n            SDK_LIST_FILE.write_text(json.dumps(sdk_list, indent=2), encoding=\"utf-8\")\n            console.print(f\"[green]Added '{platform}' to SDK list.[/green]\")\n        except Exception as e:\n            console.print(f\"[red]Failed to update SDK list: {e}[/red]\")\n\n    console.print(Panel.fit(\":white_check_mark: Scaffolding complete!\", style=\"green\"))\n\nif __name__ == \"__main__\":\n    try:\n        main()\n    except KeyboardInterrupt:\n        console.print(\"\\n[red]Interrupted by user.[/red]\")\n"
  },
  {
    "path": "tools/create_sdk.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n################################################################################\n## suite-cisco-ai-building-blocks/ai-building-blocks-agent/tools/create_sdk.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n################################################################################\n\n\"\"\"\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• OpenAPI SDK Generation Wizard â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘ A polished step-by-step CLI to run openapi-python-client for your specs.  â•‘\nâ•‘ Hover over links or type '?' at prompts for examples.                     â•‘\nâ•‘                                                                           â•‘\nâ•‘ FEATURES                                                                  â•‘\nâ•‘   â€¢ Select a single spec or generate for ALL specs                        â•‘\nâ•‘   â€¢ For each spec, optionally rename the SDK folder (defaults to stem)    â•‘\nâ•‘   â€¢ Shows the exact openapi-python-client commands in a copyable block    â•‘\nâ•‘   â€¢ At the end, lists the contents of the output_sdk directory           â•‘\nâ•‘   â€¢ Updates app/llm/sdk_list.json with any new SDK names                 â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\"\"\"\n\nimport os\nimport sys\nimport shlex\nimport subprocess\nimport json\nfrom pathlib import Path\nfrom typing import List, Dict\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\nfrom rich.table import Table\nfrom rich.markdown import Markdown\nfrom rich.tree import Tree\nfrom rich import box\nfrom rich.traceback import install\n\ninstall()\nconsole = Console()\n\n# Locate dirs\nAGENT_ROOT = Path(__file__).resolve().parents[1]\nDB_ROOT = AGENT_ROOT.parent / \"ai-building-blocks-database\"\nSOURCE_DIR = DB_ROOT / \"source_open_api\"\nOUTPUT_BASE_DIR = DB_ROOT / \"output_sdk\"\nSDK_LIST_FILE = AGENT_ROOT / \"app\" / \"llm\" / \"sdk_list.json\"\n\n\ndef clear_screen() -> None:\n    if sys.stdout.isatty():\n        os.system(\"cls\" if os.name == \"nt\" else \"clear\")\n\n\ndef list_specs() -> List[Path]:\n    specs = sorted(\n        p for p in SOURCE_DIR.iterdir()\n        if p.is_file() and p.suffix.lower() in {\".json\", \".yaml\", \".yml\"}\n    )\n    if not specs:\n        console.print(f\"[red]No OpenAPI files found in {SOURCE_DIR}[/red]\")\n        sys.exit(1)\n\n    table = Table(box=box.SIMPLE_HEAVY)\n    table.add_column(\"#\", style=\"bold cyan\")\n    table.add_column(\"Spec file\")\n    for i, p in enumerate(specs, 1):\n        table.add_row(str(i), p.name)\n    table.add_row(\"0\", \"All specs\")\n    console.print(Panel(table, title=\"Step 1/4: Select OpenAPI Spec\", border_style=\"cyan\"))\n    return specs\n\n\ndef ask_choice(prompt: str, default: str) -> str:\n    return Prompt.ask(f\"[cyan]?[/cyan] [bold]{prompt}[/bold]\", default=default).strip()\n\n\ndef build_commands(mapping: Dict[Path, str]) -> List[List[str]]:\n    cmds: List[List[str]] = []\n    for spec, sdk_name in mapping.items():\n        dest = OUTPUT_BASE_DIR / sdk_name\n        dest.mkdir(parents=True, exist_ok=True)\n        cmd = [\n            \"openapi-python-client\", \"generate\",\n            \"--path\", str(SOURCE_DIR / spec.name),\n            \"--output-path\", str(dest),\n            \"--meta\", \"poetry\",\n            \"--overwrite\",\n        ]\n        cmds.append(cmd)\n    return cmds\n\n\ndef main() -> None:\n    clear_screen()\n    console.print(Panel.fit(\"ğŸš€ OpenAPI SDK Generation Wizard\", style=\"green\"))\n\n    # Step 1: choose spec(s)\n    specs = list_specs()\n    choice = ask_choice(f\"Enter number [0-{len(specs)}]\", \"0\")\n    if choice == \"0\":\n        selected = specs\n        label = \"All specs\"\n    else:\n        try:\n            idx = int(choice)\n            selected = [specs[idx - 1]]\n            label = specs[idx - 1].name\n        except Exception:\n            console.print(\"[red]Invalid selection. Exiting.[/red]\")\n            sys.exit(1)\n    console.print(f\":white_check_mark: Selected [bold]{label}[/bold]\\n\")\n\n    # Step 2: optionally rename each SDK folder\n    mapping: Dict[Path, str] = {}\n    console.print(Panel.fit(\"ğŸ”§ Step 2/4: Name Your SDK Folders\", border_style=\"cyan\"))\n    for spec in selected:\n        default_name = spec.stem\n        sdk_name = ask_choice(f\"SDK folder name for '{spec.name}'\", default_name)\n        mapping[spec] = sdk_name\n    console.print(\":white_check_mark: Names set\\n\")\n\n    # Step 3: preview commands\n    cmds = build_commands(mapping)\n    md_blocks = \"\\n\".join(\n        \"```bash\\n\" + \" \".join(shlex.quote(p) for p in cmd) + \"\\n```\"\n        for cmd in cmds\n    )\n    console.print(\n        Panel(\n            Markdown(f\"**Commands to run**\\n{md_blocks}\"),\n            title=\"Step 3/4: Preview Commands\",\n            border_style=\"cyan\",\n        )\n    )\n\n    proceed = ask_choice(\"Proceed with SDK generation? (Y/n)\", \"Y\")\n    if proceed.lower().startswith(\"n\"):\n        console.print(\"[yellow]Aborted by user.[/yellow]\")\n        return\n\n    # Step 4: execute\n    console.print(Panel.fit(\"ğŸ›  Generating SDK(s)...\", style=\"cyan\"))\n    for cmd in cmds:\n        console.print(f\"> [bold]{' '.join(shlex.quote(p) for p in cmd)}[/bold]\")\n        result = subprocess.run(cmd)\n        if result.returncode != 0:\n            console.print(f\"[red]Failed for {cmd[-2]}[/red]\")\n        else:\n            console.print(f\"[green]Success for {cmd[-2]}[/green]\")\n\n    console.print(Panel.fit(\":white_check_mark: Generation complete!\", style=\"green\"))\n\n    # Final: list contents of output_sdk\n    console.print(Panel.fit(\"ğŸ“‚ Contents of output_sdk/\", style=\"cyan\"))\n    tree = Tree(f\"[bold]{OUTPUT_BASE_DIR.name}[/bold]\")\n    for sdk_dir in sorted(OUTPUT_BASE_DIR.iterdir()):\n        if not sdk_dir.is_dir():\n            continue\n        branch = tree.add(sdk_dir.name)\n        for child in sorted(sdk_dir.iterdir()):\n            branch.add(child.name)\n    console.print(tree)\n\n    # Update sdk_list.json with new SDK names\n    try:\n        existing = json.loads(SDK_LIST_FILE.read_text(encoding=\"utf-8\"))\n    except Exception:\n        existing = []\n    added: List[str] = []\n    for sdk_name in mapping.values():\n        if sdk_name not in existing:\n            existing.append(sdk_name)\n            added.append(sdk_name)\n    if added:\n        try:\n            SDK_LIST_FILE.parent.mkdir(parents=True, exist_ok=True)\n            SDK_LIST_FILE.write_text(json.dumps(existing, indent=2), encoding=\"utf-8\")\n            console.print(f\"[green]Added to SDK list: {', '.join(added)}[/green]\")\n        except Exception as e:\n            console.print(f\"[red]Failed to update SDK list: {e}[/red]\")\n\nif __name__ == \"__main__\":\n    try:\n        main()\n    except KeyboardInterrupt:\n        console.print(\"\\n[red]Interrupted by user.[/red]\")"
  },
  {
    "path": "tools/jaeger_collector.py",
    "content": "#!/usr/bin/env python3\nfrom __future__ import annotations\n####################################################################################\n## suite-cisco-ai-building-blocks/ai-building-blocks-agent/tools/jaeger_collector.py\n## Copyright (c) 2025 Jeff Teeter\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n####################################################################################\n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n\n\n\"\"\"\nUtility that ensures a Jaeger all-in-one OpenTelemetry collector is running.\nIf the container is missing it will be created; if it exists but is stopped\nit will be started.  The container is given a restart policy so it survives\nhost reboots and unexpected exits.\n\nRequires:  pip install docker\n\"\"\"\nfrom typing import Final\nimport docker\nfrom docker.errors import NotFound, APIError\n\nCONTAINER_NAME: Final = \"jaeger\"\nIMAGE: Final = \"jaegertracing/all-in-one:1.57\"\nPORTS: Final = {\"4317/tcp\": 4317, \"16686/tcp\": 16686}\nRESTART_POLICY: Final = {\"Name\": \"unless-stopped\"}\n\ndef main() -> None:\n    client = docker.from_env()\n\n    try:\n        container = client.containers.get(CONTAINER_NAME)\n        status = container.attrs[\"State\"][\"Status\"]\n        if status != \"running\":\n            print(f\"Starting existing container '{CONTAINER_NAME}' (was {status})â€¦\")\n            container.start()\n        else:\n            print(f\"Container '{CONTAINER_NAME}' is already running.\")\n    except NotFound:\n        print(f\"Container '{CONTAINER_NAME}' not found. Creating itâ€¦\")\n        container = client.containers.run(\n            IMAGE,\n            name=CONTAINER_NAME,\n            detach=True,\n            ports=PORTS,\n            restart_policy=RESTART_POLICY,\n        )\n        print(f\"Started new container '{CONTAINER_NAME}' ({container.short_id}).\")\n    except APIError as exc:\n        print(f\"Docker API error: {exc.explanation}\")\n        raise SystemExit(1)\n\nif __name__ == \"__main__\":\n    main()\n"
  },
  {
    "path": "tools/list_chroma_collections.py",
    "content": "#!/usr/bin/env python3\n###########################################################################################\n## suite-cisco-ai-building-blocks/ai-building-blocks-agent/tools/list_chroma_collections.py\n## Copyright (c) 2025 Jeff Teeter, Ph.D.\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n###########################################################################################\nfrom __future__ import annotations\n\n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n \n\"\"\"\nSpot-query the FASTAPI layerâ€™s Chroma DB and dump matching diet-function\nrecords to a JSONL file for manual inspection.\n\nCLI flags\n---------\n--pattern   prefix (or regex) to match against `metadata[\"name\"]`\n--platform  restrict to a single platform (omit for all)\n--outfile   where to write the JSONL (default: <pattern>_schemas.jsonl)\n\nExample usage\n-------------\n# (run these from ai-building-blocks-agent/tools)\n\n# 1. Default: find any function whose name starts with â€œgetOrganizationâ€\npython3 list_chroma_collections.py --pattern getOrganization\n\n# 2. Same pattern but restrict to the Meraki platform\npython3 list_chroma_collections.py --pattern getOrganization --platform meraki\n\n# 3. Look for functions that start with â€œclientâ€, show all platforms,\n#    and write the results to client_funcs.jsonl\npython3 list_chroma_collections.py --pattern client --outfile client_funcs.jsonl\n\n\"\"\"\n\n\n# â”€â”€ standard libs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport argparse\nimport json\nimport os\nimport re\nimport sys\nfrom pathlib import Path\n\n# â”€â”€ repo-root on sys.path so imports work from any cwd â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nREPO_ROOT = Path(__file__).resolve().parents[1]          # â€¦/ai-building-blocks-agent\nif str(REPO_ROOT) not in sys.path:\n    sys.path.insert(0, str(REPO_ROOT))\n\n# â”€â”€ third-party â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfrom dotenv import load_dotenv\nimport chromadb\nfrom chromadb.config import Settings\n\n# â”€â”€ internal helper to canonicalise paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfrom scripts.utils.paths import ensure_abs_env\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 1.  Parse CLI flags\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nap = argparse.ArgumentParser(description=\"Dump matching diet-function records \"\n                                         \"from the FASTAPI Chroma DB.\")\nap.add_argument(\"--pattern\", default=\"getOrganization\",\n                help=\"prefix (or full regex) to match (default: getOrganization)\")\nap.add_argument(\"--platform\", default=None,\n                help=\"platform filter (e.g. meraki); omit for all\")\nap.add_argument(\"--outfile\", default=None,\n                help=\"output path; default is <pattern>_schemas.jsonl \"\n                     \"in the same folder as this script\")\nargs = ap.parse_args()\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 2.  Resolve env-vars + open Chroma collection\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nload_dotenv(REPO_ROOT.parent / \".env\")\n\nDB_ROOT = ensure_abs_env(\"FASTAPI_CHROMA_DB_PATH\", \"chroma_dbs/fastapi\")\nCOL_NAME = os.getenv(\"FASTAPI_CHROMA_COLLECTION_PLATFORM\",\n                     \"function-definitions-index\")\nCOL_DIR = DB_ROOT / COL_NAME\nclient = chromadb.PersistentClient(\n    path=str(COL_DIR),\n    settings=Settings(anonymized_telemetry=False),\n)\ncol = client.get_or_create_collection(COL_NAME)\nprint(f\"Collection '{COL_NAME}' has {col.count()} vectors\")\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 3.  Fetch and filter\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nregex = re.compile(rf\"{args.pattern}\")\nhits = []\n\ndata = col.get()   # pulls all ids/docs/metas\nfor _id, meta, doc in zip(data[\"ids\"], data[\"metadatas\"], data[\"documents\"]):\n    if args.platform and meta.get(\"platform\") != args.platform:\n        continue\n    name = meta.get(\"name\", \"\")\n    if regex.match(name):\n        hits.append({\n            \"id\": _id,\n            \"name\": name,\n            \"metadata\": meta,\n            \"schema\": json.loads(doc),\n        })\n\nprint(f\"Found {len(hits)} matching schemas \"\n      f\"for pattern '{args.pattern}'\"\n      f\"{' in platform ' + args.platform if args.platform else ''}\")\n\n# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n# 4.  Write JSONL next to this script (or custom path)\n# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nscript_dir = Path(__file__).parent.resolve()\noutfile = Path(args.outfile) if args.outfile else \\\n          script_dir / f\"{args.pattern}_schemas.jsonl\"\n\nwith outfile.open(\"w\", encoding=\"utf-8\") as fh:\n    for rec in hits:\n        fh.write(json.dumps(rec) + \"\\n\")\n\nprint(f\"Wrote {len(hits)} records â†’ {outfile.resolve()}\")\n"
  },
  {
    "path": "tools/reset_automated_folders.py",
    "content": "#!/usr/bin/env python3\n###########################################################################################\n## suite-cisco-ai-building-blocks/ai-building-blocks-agent/tools/reset_automated_folders.py\n## Copyright (c) 2025 Jeff Teeter, Ph.D.\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n###########################################################################################\nfrom __future__ import annotations\n\n\"\"\"\nDISCLAIMER: USE AT YOUR OWN RISK\n\nThis software is provided \"as is\", without any express or implied warranties, including, but not limited to,\nthe implied warranties of merchantability and fitness for a particular purpose. In no event shall the authors or\ncontributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages\n(including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits;\nor business interruption) however caused and on any theory of liability, whether in contract, strict liability,\nor tort (including negligence or otherwise) arising in any way out of the use of this software.\n\nThis script is provided for demonstration and development purposes only and is not intended for use in production\nenvironments. You are solely responsible for any modifications or adaptations made for your specific use case.\n\nBy using this code, you agree that you have read, understood, and accept these terms.\n\"\"\"\n\n\"\"\"\nUtility to wipe and recreate all auto-generated LLM folders\n(app/llm/function_definitions, openapi_specs, â€¦).\n\nLaunch it from anywhere; it always operates on the folders inside the\nai-building-blocks-agent repo and prints what it deleted / rebuilt.\n\"\"\"\nfrom pathlib import Path\nimport shutil\nimport sys\nimport os\n\n# â”€â”€ repo root discovery so script works from any cwd â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nREPO_ROOT = Path(__file__).resolve().parents[1]         # â€¦/ai-building-blocks-agent\nif str(REPO_ROOT) not in sys.path:                      # (not strictly needed here,\n    sys.path.insert(0, str(REPO_ROOT))                  #  but matches the pattern)\n\n# â”€â”€ target folders (absolute paths) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nFOLDERS_TO_RESET = [\n    REPO_ROOT / \"app\" / \"llm\" / \"function_definitions\",\n    REPO_ROOT / \"app\" / \"llm\" / \"openapi_specs\",\n    REPO_ROOT / \"app\" / \"llm\" / \"platform_clients\",\n    REPO_ROOT / \"app\" / \"llm\" / \"function_dispatcher\",\n    REPO_ROOT / \"app\" / \"llm\" / \"unified_service\",\n]\n\ndef reset_folders(paths: list[Path]) -> None:\n    \"\"\"Delete each folder if present, then recreate it empty.\"\"\"\n    for folder in paths:\n        if folder.exists():\n            print(f\"Deleting  â†’ {folder.relative_to(REPO_ROOT)}\")\n            shutil.rmtree(folder)\n        else:\n            print(f\"Not found  â†’ {folder.relative_to(REPO_ROOT)} (skip delete)\")\n\n        folder.mkdir(parents=True, exist_ok=True)\n        print(f\"Recreated â†’ {folder.relative_to(REPO_ROOT)}\\n\")\n\nif __name__ == \"__main__\":\n    reset_folders(FOLDERS_TO_RESET)\n    print(\"âœ… All automated folders have been reset.\")\n"
  },
  {
    "path": "tools/test_chroma_retriever.py",
    "content": "#!/usr/bin/env python3\n###########################################################################################\n## suite-cisco-ai-building-blocks/ai-building-blocks-agent/tools/test_chroma_retriever.py\n## Copyright (c) 2025 Jeff Teeter, Ph.D.\n## Cisco Systems, Inc.\n## Licensed under the Apache License, Version 2.0 (see LICENSE)\n## Distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.\n###########################################################################################\nfrom __future__ import annotations\n\n\"\"\"\nSmoke-test the Chroma **FunctionRetriever**.\n\nIt works from any directory: the script locates the repo root, fixes\n`FASTAPI_CHROMA_DB_PATH` (turning a relative value into an absolute path),\nthen runs one or two demo searches and prints the distance-sorted results.\n\nCLI flags\n---------\n--term        search term for the vector query        (default: \"organization\")\n--platform    restrict results to a single platform   (omit for no filter)\n--top-k       how many hits to show                   (default: 5)\n\nExample usage\n-------------\n# â”€â”€ launch from the tools/ folder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\npython3 test_chroma_retriever.py                       # default: term=\"organization\"\npython3 test_chroma_retriever.py --term client --top-k 10\npython3 test_chroma_retriever.py --term site --platform meraki\n\n# â”€â”€ launch from the repo root (or anywhere) using -m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\npython -m ai_building_blocks_agent.tools.test_chroma_retriever \\\n       --term site --platform meraki\n\"\"\"\n\nimport argparse\nimport os\nimport sys\nfrom pathlib import Path\n\n# â”€â”€ ensure repo root is importable â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nREPO_ROOT = Path(__file__).resolve().parents[1]          # â€¦/ai-building-blocks-agent\nif str(REPO_ROOT) not in sys.path:\n    sys.path.insert(0, str(REPO_ROOT))\n\n# â”€â”€ canonicalise Chroma DB path (relative â†’ absolute) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfrom scripts.utils.paths import ensure_abs_env\nensure_abs_env(\"FASTAPI_CHROMA_DB_PATH\", \"chroma_dbs/fastapi\")\n\nfrom retrievers.chroma_retriever import FunctionRetriever\n\n\ndef print_results(results: list[dict]) -> None:\n    for i, r in enumerate(results, 1):\n        print(f\"  {i:>2}. \"\n              f\"name={r.get('name'):<60} \"\n              f\"platform={r.get('platform'):<10} \"\n              f\"distance={r.get('distance'):.4f}\")\n\n\ndef main() -> None:\n    # â”€â”€ CLI flags â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    ap = argparse.ArgumentParser(description=\"Quick query against Chroma.\")\n    ap.add_argument(\"--term\",      default=\"organization\",\n                    help=\"vector query term (default: 'organization')\")\n    ap.add_argument(\"--platform\",  default=None,\n                    help=\"platform filter, e.g. meraki (omit for no filter)\")\n    ap.add_argument(\"--top-k\",     type=int, default=5,\n                    help=\"how many top hits to display (default: 5)\")\n    args = ap.parse_args()\n\n    collection = os.getenv(\"FASTAPI_CHROMA_COLLECTION_PLATFORM\",\n                           \"function-definitions-index\")\n    print(f\"\\nInitializing FunctionRetriever against collection \"\n          f\"'{collection}' â€¦\\n\")\n    retriever = FunctionRetriever(collection_name=collection)\n\n    # â”€â”€ query without platform filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    print(f\"1) Top-{args.top_k} schemas for query '{args.term}':\")\n    hits = retriever.query(args.term, k=args.top_k)\n    print_results(hits)\n    print(f\"  â†’ Retrieved {len(hits)} entries\\n\")\n\n    # â”€â”€ optional platform-specific query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    if args.platform:\n        print(f\"2) Top-{args.top_k} schemas for '{args.term}' \"\n              f\"on platform '{args.platform}':\")\n        hits = retriever.query(\n            args.term,\n            k=args.top_k,\n            filter={\"platform\": {\"$in\": [args.platform]}}\n        )\n        print_results(hits)\n        print(f\"  â†’ Retrieved {len(hits)} entries\\n\")\n\n\nif __name__ == \"__main__\":\n    main()\n"
  }
]